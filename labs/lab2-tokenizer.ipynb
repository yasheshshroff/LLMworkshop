{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **LAB 2: FINE TUNING**\n\nFine-tuning refers to the process of taking a pre-trained language model and \ntraining it further on a specific task or domain to improve its performance on that task.  \n<br />\nIt is an important technique used to adapt LLMs to specific tasks and domains.  \n<br />\nIn this lab we will explore basic ways to fine tune large language models using\nopen soure tools. First we look at an example of doing this by hand with the open source ðŸ¤— Transformers\nPython library. Familiarity with the ðŸ¤— Transformers package is helpful once we\nintroduce additional tools with more flexibility, such as H2O LLM Studio  \n<br />\nIn this notebook, we will explore how do fine-tune a foundational large language\nmodel such that it can generate LinkedIn posts in the style of known influencers\non the platform. \n\nUse the prepared dataset from the prior lab: /kaggle/input/influencers-data-prepared-csv\n- You will need to click on `Add Data`, \n- Select `Your Datasets`,  \n- Grab the `requirements`, and \n- Grab the `influencers_data_prepared.csv` datasets","metadata":{}},{"cell_type":"markdown","source":"# Using Hugging Face \n\n## Understanding the `transformers` and `datasets` libraries\n\n- Load the WNLI data set from the General Language Understanding Evaluation (GLUE)\nbenchmark. (https://gluebenchmark.com/)\n\nFrom the paper, `The Winograd Schema Challenge (Levesque et al., 2011)`, this is a reading comprehension task\nin which a system must read a sentence with a pronoun and select the referent of that pronoun from\na list of choices.`\n\n**If you are on Kaggle, set the Accelerator to \"GPU-T4\"**\n\n**References**:\n- Datasets library: https://pypi.org/project/datasets/","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\n# set flag for training environment\nTRAINING = True\n\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, DataCollatorWithPadding\n\nraw_datasets = load_dataset(\"glue\", \"wnli\")\ncheckpoint = \"bert-base-uncased\"\n","metadata":{"execution":{"iopub.status.busy":"2023-11-10T16:20:57.171696Z","iopub.execute_input":"2023-11-10T16:20:57.172396Z","iopub.status.idle":"2023-11-10T16:21:23.758079Z","shell.execute_reply.started":"2023-11-10T16:20:57.172353Z","shell.execute_reply":"2023-11-10T16:21:23.756773Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.78k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"112b532d617d4ce4a0aad096d9bd0797"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/4.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5c7847137994849a748fe7dcd8a2cc5"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset glue/wnli (download: 28.32 KiB, generated: 154.03 KiB, post-processed: Unknown size, total: 182.35 KiB) to /root/.cache/huggingface/datasets/glue/wnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/29.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78174d8087174270ab5cf5a6d2ba69e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/635 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/71 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/146 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/wnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1cded8f1fef4101adb3fce618173b54"}},"metadata":{}}]},{"cell_type":"code","source":"glue_dataset = load_dataset(\"glue\", \"wnli\")\nglue_dataset","metadata":{"execution":{"iopub.status.busy":"2023-11-10T16:30:20.870574Z","iopub.execute_input":"2023-11-10T16:30:20.871059Z","iopub.status.idle":"2023-11-10T16:30:22.023419Z","shell.execute_reply.started":"2023-11-10T16:30:20.871022Z","shell.execute_reply":"2023-11-10T16:30:22.022544Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4cb860b849b43d7b1bf25111289ab02"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 635\n    })\n    validation: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 71\n    })\n    test: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 146\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets","metadata":{"execution":{"iopub.status.busy":"2023-11-10T16:27:30.356871Z","iopub.execute_input":"2023-11-10T16:27:30.357379Z","iopub.status.idle":"2023-11-10T16:27:30.367209Z","shell.execute_reply.started":"2023-11-10T16:27:30.357343Z","shell.execute_reply":"2023-11-10T16:27:30.365682Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 635\n    })\n    validation: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 71\n    })\n    test: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 146\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets['test'].__dir__()","metadata":{"execution":{"iopub.status.busy":"2023-11-10T05:30:21.405404Z","iopub.execute_input":"2023-11-10T05:30:21.406330Z","iopub.status.idle":"2023-11-10T05:30:21.418724Z","shell.execute_reply.started":"2023-11-10T05:30:21.406281Z","shell.execute_reply":"2023-11-10T05:30:21.417614Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"['_info',\n '_split',\n '_indexes',\n '_data',\n '_indices',\n '_format_type',\n '_format_kwargs',\n '_format_columns',\n '_output_all_columns',\n '_fingerprint',\n '__module__',\n '__doc__',\n '__init__',\n 'from_file',\n 'from_buffer',\n 'from_pandas',\n 'from_dict',\n 'from_csv',\n 'from_json',\n 'from_parquet',\n 'from_text',\n '__del__',\n '__enter__',\n '__exit__',\n 'save_to_disk',\n '_build_local_temp_path',\n 'load_from_disk',\n 'data',\n 'cache_files',\n 'num_columns',\n 'num_rows',\n 'column_names',\n 'shape',\n 'unique',\n 'class_encode_column',\n 'flatten',\n 'cast',\n 'cast_column',\n 'remove_columns',\n 'rename_column',\n 'rename_columns',\n '__len__',\n '_iter',\n '__iter__',\n '__repr__',\n 'format',\n 'formatted_as',\n 'set_format',\n 'reset_format',\n 'set_transform',\n 'with_format',\n 'with_transform',\n 'prepare_for_task',\n '_getitem',\n '__getitem__',\n 'cleanup_cache_files',\n '_get_cache_file_path',\n 'map',\n '_map_single',\n 'filter',\n 'flatten_indices',\n '_new_dataset_with_indices',\n 'select',\n 'sort',\n 'shuffle',\n 'train_test_split',\n 'shard',\n 'export',\n 'to_csv',\n 'to_dict',\n 'to_json',\n 'to_pandas',\n 'to_parquet',\n '_push_parquet_shards_to_hub',\n 'push_to_hub',\n 'add_column',\n 'add_faiss_index',\n 'add_faiss_index_from_external_arrays',\n 'add_elasticsearch_index',\n 'add_item',\n 'align_labels_with_mapping',\n '__slotnames__',\n 'info',\n 'split',\n 'builder_name',\n 'citation',\n 'config_name',\n 'dataset_size',\n 'description',\n 'download_checksums',\n 'download_size',\n 'features',\n 'homepage',\n 'license',\n 'size_in_bytes',\n 'supervised_keys',\n 'task_templates',\n 'version',\n '__dict__',\n '__weakref__',\n '__new__',\n '__hash__',\n '__str__',\n '__getattribute__',\n '__setattr__',\n '__delattr__',\n '__lt__',\n '__le__',\n '__eq__',\n '__ne__',\n '__gt__',\n '__ge__',\n '__reduce_ex__',\n '__reduce__',\n '__subclasshook__',\n '__init_subclass__',\n '__format__',\n '__sizeof__',\n '__dir__',\n '__class__',\n 'is_index_initialized',\n '_check_index_is_initialized',\n 'list_indexes',\n 'get_index',\n 'save_faiss_index',\n 'load_faiss_index',\n 'load_elasticsearch_index',\n 'drop_index',\n 'search',\n 'search_batch',\n 'get_nearest_examples',\n 'get_nearest_examples_batch',\n '_TF_DATASET_REFS',\n '_get_output_signature',\n 'to_tf_dataset']"},"metadata":{}}]},{"cell_type":"code","source":"from pprint import pprint\npprint(raw_datasets['test']._info)","metadata":{"execution":{"iopub.status.busy":"2023-11-10T05:35:21.497601Z","iopub.execute_input":"2023-11-10T05:35:21.497994Z","iopub.status.idle":"2023-11-10T05:35:21.522838Z","shell.execute_reply.started":"2023-11-10T05:35:21.497964Z","shell.execute_reply":"2023-11-10T05:35:21.521817Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"DatasetInfo(description='GLUE, the General Language Understanding Evaluation '\n                        'benchmark\\n'\n                        '(https://gluebenchmark.com/) is a collection of '\n                        'resources for training,\\n'\n                        'evaluating, and analyzing natural language '\n                        'understanding systems.\\n'\n                        '\\n',\n            citation='@inproceedings{levesque2012winograd,\\n'\n                     '  title={The winograd schema challenge},\\n'\n                     '  author={Levesque, Hector and Davis, Ernest and '\n                     'Morgenstern, Leora},\\n'\n                     '  booktitle={Thirteenth International Conference on the '\n                     'Principles of Knowledge Representation and Reasoning},\\n'\n                     '  year={2012}\\n'\n                     '}\\n'\n                     '@inproceedings{wang2019glue,\\n'\n                     '  title={{GLUE}: A Multi-Task Benchmark and Analysis '\n                     'Platform for Natural Language Understanding},\\n'\n                     '  author={Wang, Alex and Singh, Amanpreet and Michael, '\n                     'Julian and Hill, Felix and Levy, Omer and Bowman, Samuel '\n                     'R.},\\n'\n                     '  note={In the Proceedings of ICLR.},\\n'\n                     '  year={2019}\\n'\n                     '}\\n',\n            homepage='https://cs.nyu.edu/faculty/davise/papers/WinogradSchemas/WS.html',\n            license='',\n            features={'idx': Value(dtype='int32', id=None),\n                      'label': ClassLabel(num_classes=2,\n                                          names=['not_entailment',\n                                                 'entailment'],\n                                          id=None),\n                      'sentence1': Value(dtype='string', id=None),\n                      'sentence2': Value(dtype='string', id=None)},\n            post_processed=None,\n            supervised_keys=None,\n            task_templates=None,\n            builder_name='glue',\n            config_name='wnli',\n            version=1.0.0,\n            splits={'test': SplitInfo(name='test',\n                                      num_bytes=37889,\n                                      num_examples=146,\n                                      dataset_name='glue'),\n                    'train': SplitInfo(name='train',\n                                       num_bytes=107109,\n                                       num_examples=635,\n                                       dataset_name='glue'),\n                    'validation': SplitInfo(name='validation',\n                                            num_bytes=12162,\n                                            num_examples=71,\n                                            dataset_name='glue')},\n            download_checksums={'https://dl.fbaipublicfiles.com/glue/data/WNLI.zip': {'checksum': 'ae0e8e4d16f4d46d4a0a566ec7ecceccfd3fbfaa4a7a4b4e02848c0f2561ac46',\n                                                                                      'num_bytes': 28999}},\n            download_size=28999,\n            post_processing_size=None,\n            dataset_size=157160,\n            size_in_bytes=186159)\n","output_type":"stream"}]},{"cell_type":"code","source":"raw_datasets['train'][2:4]","metadata":{"execution":{"iopub.status.busy":"2023-11-10T05:40:20.845495Z","iopub.execute_input":"2023-11-10T05:40:20.845888Z","iopub.status.idle":"2023-11-10T05:40:20.854723Z","shell.execute_reply.started":"2023-11-10T05:40:20.845855Z","shell.execute_reply":"2023-11-10T05:40:20.853566Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"{'sentence1': ['The police arrested all of the gang members. They were trying to stop the drug trade in the neighborhood.',\n  \"Steve follows Fred's example in everything. He influences him hugely.\"],\n 'sentence2': ['The police were trying to stop the drug trade in the neighborhood.',\n  'Steve influences him hugely.'],\n 'label': [1, 0],\n 'idx': [2, 3]}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Tokenizer\n\nWe can automatically load the correct tokenizer used from the pretrained model\nvia `AutoTokenizer`.","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\nsequence = 'this will be fun!'\n\ntokenizer.tokenize(sequence)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-10T16:24:29.271806Z","iopub.execute_input":"2023-11-10T16:24:29.272899Z","iopub.status.idle":"2023-11-10T16:24:32.881120Z","shell.execute_reply.started":"2023-11-10T16:24:29.272850Z","shell.execute_reply":"2023-11-10T16:24:32.880077Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"375750b1ab0442e1995f5b1ff5edb9c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab9e8c247f47402eb7c4f42e4b1bf03d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47b14e658b8a49db85ace36e4356f163"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"087c965ebbe44cba8d51e012bcde4c37"}},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"['this', 'will', 'be', 'fun', '!']"},"metadata":{}}]},{"cell_type":"markdown","source":"# Tokenizer Output\n\nLet's take a look at the integers (input_ids) assigned to each token in the sequence\nas well as other information such as optional masks for any tokens that need to be\nmasked from the attention mechanism - special tokens for truncating sequences for example","metadata":{}},{"cell_type":"code","source":"tokenizer(sequence)","metadata":{"execution":{"iopub.status.busy":"2023-11-10T16:24:36.031048Z","iopub.execute_input":"2023-11-10T16:24:36.032076Z","iopub.status.idle":"2023-11-10T16:24:36.039897Z","shell.execute_reply.started":"2023-11-10T16:24:36.032035Z","shell.execute_reply":"2023-11-10T16:24:36.038947Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101, 2023, 2097, 2022, 4569, 999, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"# function to create\ndef tokenize_function(example):\n    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n\ntokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-11-10T16:24:57.934974Z","iopub.execute_input":"2023-11-10T16:24:57.935458Z","iopub.status.idle":"2023-11-10T16:24:58.140370Z","shell.execute_reply.started":"2023-11-10T16:24:57.935411Z","shell.execute_reply":"2023-11-10T16:24:58.139149Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46146945abd04d02a2477aea74b737c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdf469a65ed042cc990adbe7d486db08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63e886acc9de485294c7963dc814f5fb"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\"test-trainer\")","metadata":{"execution":{"iopub.status.busy":"2023-11-10T05:23:11.315585Z","iopub.execute_input":"2023-11-10T05:23:11.316558Z","iopub.status.idle":"2023-11-10T05:23:11.552216Z","shell.execute_reply.started":"2023-11-10T05:23:11.316521Z","shell.execute_reply":"2023-11-10T05:23:11.551454Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Load pretrained model weights","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2023-11-10T05:23:13.109981Z","iopub.execute_input":"2023-11-10T05:23:13.110399Z","iopub.status.idle":"2023-11-10T05:23:23.684655Z","shell.execute_reply.started":"2023-11-10T05:23:13.110366Z","shell.execute_reply":"2023-11-10T05:23:23.683697Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b638809f8924f4b88b14a8b543b2c16"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Create a Trainer object to begin fine tuning","metadata":{}},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-10T05:23:42.828859Z","iopub.execute_input":"2023-11-10T05:23:42.829564Z","iopub.status.idle":"2023-11-10T05:23:48.939251Z","shell.execute_reply.started":"2023-11-10T05:23:42.829524Z","shell.execute_reply":"2023-11-10T05:23:48.938267Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-11-10T05:23:54.625741Z","iopub.execute_input":"2023-11-10T05:23:54.626655Z","iopub.status.idle":"2023-11-10T05:25:38.277312Z","shell.execute_reply.started":"2023-11-10T05:23:54.626617Z","shell.execute_reply":"2023-11-10T05:25:38.276139Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.12"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231110_052433-2po6lytq</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/optixlab/huggingface/runs/2po6lytq' target=\"_blank\">different-totem-1</a></strong> to <a href='https://wandb.ai/optixlab/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/optixlab/huggingface' target=\"_blank\">https://wandb.ai/optixlab/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/optixlab/huggingface/runs/2po6lytq' target=\"_blank\">https://wandb.ai/optixlab/huggingface/runs/2po6lytq</a>"},"metadata":{}},{"name":"stderr","text":"You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [120/120 00:27, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=120, training_loss=0.7066105524698894, metrics={'train_runtime': 103.3614, 'train_samples_per_second': 18.43, 'train_steps_per_second': 1.161, 'total_flos': 72598609616940.0, 'train_loss': 0.7066105524698894, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Generate predictions on the validation data","metadata":{}},{"cell_type":"code","source":"predictions = trainer.predict(tokenized_datasets[\"validation\"])\nprint(predictions.predictions.shape, predictions.label_ids.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-10T05:25:54.487348Z","iopub.execute_input":"2023-11-10T05:25:54.487745Z","iopub.status.idle":"2023-11-10T05:25:54.940922Z","shell.execute_reply.started":"2023-11-10T05:25:54.487712Z","shell.execute_reply":"2023-11-10T05:25:54.939863Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"(71, 2) (71,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model Output\n\nAs we can see, the transformer model outputs logits directly","metadata":{}},{"cell_type":"code","source":"print(predictions.predictions[:10, :10])","metadata":{"execution":{"iopub.status.busy":"2023-11-10T05:25:58.434139Z","iopub.execute_input":"2023-11-10T05:25:58.434504Z","iopub.status.idle":"2023-11-10T05:25:58.445034Z","shell.execute_reply.started":"2023-11-10T05:25:58.434477Z","shell.execute_reply":"2023-11-10T05:25:58.443526Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"[[ 0.06643731  0.23543179]\n [ 0.14411297  0.22523996]\n [ 0.11989371  0.24879391]\n [ 0.2413762   0.22958633]\n [ 0.16321541  0.18696262]\n [ 0.11199773  0.2538352 ]\n [ 0.12315273  0.23112205]\n [ 0.19100055  0.18159585]\n [-0.14954926  0.10492721]\n [-0.07249562  0.05665697]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Turn into label predictions","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\npreds = np.argmax(predictions.predictions, axis=-1)\npreds","metadata":{"execution":{"iopub.status.busy":"2023-11-10T05:26:03.800878Z","iopub.execute_input":"2023-11-10T05:26:03.801280Z","iopub.status.idle":"2023-11-10T05:26:03.810854Z","shell.execute_reply.started":"2023-11-10T05:26:03.801250Z","shell.execute_reply":"2023-11-10T05:26:03.809928Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array([1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n       1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n       1, 1, 0, 1, 1])"},"metadata":{}}]},{"cell_type":"markdown","source":"---","metadata":{}}]}