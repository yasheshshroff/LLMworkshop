{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc0ed12c",
   "metadata": {},
   "source": [
    "# **LAB 3: LLM EVALUATION**\n",
    "\n",
    "<br>\n",
    "\n",
    "This lab will leverage a running instance of h2oGPT with several visible models\n",
    "including `h2oGPT-llama2-13b` and `h2oGPT-llama2-70b`, as well as `vicuna` from\n",
    "LMSYS. \n",
    "\n",
    "We will return to our use case surrounding training a language model to speak\n",
    "like a LinkedIn Influencer. Here we will ask h2oGPT to generate LinkedIn posts\n",
    "in the style of an influencer from several models, and we will also use the model\n",
    "you created using H2O LLM Studio.\n",
    "\n",
    "We will run a few experiments to look at classic evaluation metrics such as BLEU \n",
    "and ROUGE. Then we will look at the AI-as-a-judge concept\n",
    "\n",
    "### Getting started\n",
    "- If you are on Kaggle, grab the requirements and processed influencer datasets from the right panel\n",
    "  - Click on \"Add Data\"\n",
    "  - Go to \"Your Datasets\"\n",
    "  - Select datasets with the \"+\" symbol\n",
    " \n",
    "- Notebook options\n",
    "  - Select GPU T4 x2 (note the quota)\n",
    "  - Persistence: Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde2ebd1",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc1a583c",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-11-10T21:08:57.282783Z",
     "iopub.status.busy": "2023-11-10T21:08:57.282466Z",
     "iopub.status.idle": "2023-11-10T21:12:58.011925Z",
     "shell.execute_reply": "2023-11-10T21:12:58.010735Z",
     "shell.execute_reply.started": "2023-11-10T21:08:57.282756Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting absl-py==2.0.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 1))\n",
      "  Obtaining dependency information for absl-py==2.0.0 from https://files.pythonhosted.org/packages/01/e4/dc0a1dcc4e74e08d7abedab278c795eef54a224363bb18f5692f416d834f/absl_py-2.0.0-py3-none-any.whl.metadata\n",
      "  Using cached absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting accelerate==0.24.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 2))\n",
      "  Obtaining dependency information for accelerate==0.24.0 from https://files.pythonhosted.org/packages/d0/cf/364d550af711b5abe5129ac676896b223ba5a082d97fe400527a59c0c1f8/accelerate-0.24.0-py3-none-any.whl.metadata\n",
      "  Using cached accelerate-0.24.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting aiobotocore==2.7.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 3))\n",
      "  Obtaining dependency information for aiobotocore==2.7.0 from https://files.pythonhosted.org/packages/d0/bc/6a96a686845c9f5958fac0ecafa6050ed77d0e71553b3cfe69acbaa70191/aiobotocore-2.7.0-py3-none-any.whl.metadata\n",
      "  Using cached aiobotocore-2.7.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting aiohttp==3.8.5 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 4))\n",
      "  Obtaining dependency information for aiohttp==3.8.5 from https://files.pythonhosted.org/packages/3e/f6/fcda07dd1e72260989f0b22dde999ecfe80daa744f23ca167083683399bc/aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting aioitertools==0.11.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 5))\n",
      "  Using cached aioitertools-0.11.0-py3-none-any.whl (23 kB)\n",
      "Collecting aiosignal==1.3.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 6))\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting alembic==1.12.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 7))\n",
      "  Obtaining dependency information for alembic==1.12.1 from https://files.pythonhosted.org/packages/34/47/95d8f99c9f4a57079dfbcff5e023c5d81bde092d1c2354156340a56b3a1a/alembic-1.12.1-py3-none-any.whl.metadata\n",
      "  Using cached alembic-1.12.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting alt-profanity-check==1.3.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 8))\n",
      "  Using cached alt_profanity_check-1.3.1-py3-none-any.whl\n",
      "Collecting annoy==1.17.3 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 9))\n",
      "  Using cached annoy-1.17.3-cp310-cp310-linux_x86_64.whl\n",
      "Collecting anyio==4.0.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 10))\n",
      "  Obtaining dependency information for anyio==4.0.0 from https://files.pythonhosted.org/packages/36/55/ad4de788d84a630656ece71059665e01ca793c04294c463fd84132f40fe6/anyio-4.0.0-py3-none-any.whl.metadata\n",
      "  Using cached anyio-4.0.0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting async-timeout==4.0.3 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 11))\n",
      "  Obtaining dependency information for async-timeout==4.0.3 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting attrs==23.1.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 12))\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting beautifulsoup4==4.12.2 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 13))\n",
      "  Using cached beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
      "Collecting blessed==1.20.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 14))\n",
      "  Using cached blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting blinker==1.7.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 15))\n",
      "  Obtaining dependency information for blinker==1.7.0 from https://files.pythonhosted.org/packages/fa/2a/7f3714cbc6356a0efec525ce7a0613d581072ed6eb53eb7b9754f33db807/blinker-1.7.0-py3-none-any.whl.metadata\n",
      "  Using cached blinker-1.7.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting botocore==1.31.64 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 16))\n",
      "  Obtaining dependency information for botocore==1.31.64 from https://files.pythonhosted.org/packages/d0/68/6a9c405bc6c6e7d832743a458c87f21cee393ef2cf32437a0a3a07cd0ae9/botocore-1.31.64-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.31.64-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting bs4==0.0.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 17))\n",
      "  Using cached bs4-0.0.1-py3-none-any.whl\n",
      "Collecting cachetools==5.3.2 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 18))\n",
      "  Obtaining dependency information for cachetools==5.3.2 from https://files.pythonhosted.org/packages/a2/91/2d843adb9fbd911e0da45fbf6f18ca89d07a087c3daa23e955584f90ebf4/cachetools-5.3.2-py3-none-any.whl.metadata\n",
      "  Using cached cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting certifi==2023.7.22 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 19))\n",
      "  Obtaining dependency information for certifi==2023.7.22 from https://files.pythonhosted.org/packages/4c/dd/2234eab22353ffc7d94e8d13177aaa050113286e93e7b40eae01fbf7c3d9/certifi-2023.7.22-py3-none-any.whl.metadata\n",
      "  Using cached certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting charset-normalizer==3.3.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 20))\n",
      "  Obtaining dependency information for charset-normalizer==3.3.1 from https://files.pythonhosted.org/packages/87/80/f0974891fdd2e756f3f4941cfca870826ba0260752ee3dc28dee4af7e401/charset_normalizer-3.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached charset_normalizer-3.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting click==8.1.7 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 21))\n",
      "  Obtaining dependency information for click==8.1.7 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting cloudpickle==2.2.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 22))\n",
      "  Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting colorama==0.4.6 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 23))\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting contourpy==1.1.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 24))\n",
      "  Obtaining dependency information for contourpy==1.1.1 from https://files.pythonhosted.org/packages/f1/6b/e4b0f8708f22dd7c321f87eadbb98708975e115ac6582eb46d1f32197ce6/contourpy-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached contourpy-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
      "Collecting cycler==0.12.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 25))\n",
      "  Obtaining dependency information for cycler==0.12.1 from https://files.pythonhosted.org/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl.metadata\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting databricks-cli==0.18.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 26))\n",
      "  Obtaining dependency information for databricks-cli==0.18.0 from https://files.pythonhosted.org/packages/ae/a3/d56f8382c40899301f327d1c881278b09c9b8bc301c2c111633a0346d06e/databricks_cli-0.18.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached databricks_cli-0.18.0-py2.py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting dataclasses-json==0.5.14 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 27))\n",
      "  Obtaining dependency information for dataclasses-json==0.5.14 from https://files.pythonhosted.org/packages/97/5f/e7cc90f36152810cab08b6c9c1125e8bcb9d76f8b3018d101b5f877b386c/dataclasses_json-0.5.14-py3-none-any.whl.metadata\n",
      "  Using cached dataclasses_json-0.5.14-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting datasets==2.14.6 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 28))\n",
      "  Obtaining dependency information for datasets==2.14.6 from https://files.pythonhosted.org/packages/7c/55/b3432f43d6d7fee999bb23a547820d74c48ec540f5f7842e41aa5d8d5f3a/datasets-2.14.6-py3-none-any.whl.metadata\n",
      "  Using cached datasets-2.14.6-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting dill==0.3.7 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 29))\n",
      "  Obtaining dependency information for dill==0.3.7 from https://files.pythonhosted.org/packages/f5/3a/74a29b11cf2cdfcd6ba89c0cecd70b37cd1ba7b77978ce611eb7a146a832/dill-0.3.7-py3-none-any.whl.metadata\n",
      "  Using cached dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting docker==6.1.3 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 30))\n",
      "  Obtaining dependency information for docker==6.1.3 from https://files.pythonhosted.org/packages/db/be/3032490fa33b36ddc8c4b1da3252c6f974e7133f1a50de00c6b85cca203a/docker-6.1.3-py3-none-any.whl.metadata\n",
      "  Using cached docker-6.1.3-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting entrypoints==0.4 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 31))\n",
      "  Using cached entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Collecting evaluate==0.4.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 32))\n",
      "  Obtaining dependency information for evaluate==0.4.1 from https://files.pythonhosted.org/packages/70/63/7644a1eb7b0297e585a6adec98ed9e575309bb973c33b394dae66bc35c69/evaluate-0.4.1-py3-none-any.whl.metadata\n",
      "  Using cached evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting fastapi==0.96.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 33))\n",
      "  Obtaining dependency information for fastapi==0.96.0 from https://files.pythonhosted.org/packages/b4/61/b62cd764a6d23220e5e8195405f6926643a41b088d3de550407e8a4edd80/fastapi-0.96.0-py3-none-any.whl.metadata\n",
      "  Using cached fastapi-0.96.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting filelock==3.12.4 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 34))\n",
      "  Obtaining dependency information for filelock==3.12.4 from https://files.pythonhosted.org/packages/5e/5d/97afbafd9d584ff1b45fcb354a479a3609bd97f912f8f1f6c563cb1fae21/filelock-3.12.4-py3-none-any.whl.metadata\n",
      "  Using cached filelock-3.12.4-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting Flask==3.0.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 35))\n",
      "  Obtaining dependency information for Flask==3.0.0 from https://files.pythonhosted.org/packages/36/42/015c23096649b908c809c69388a805a571a3bea44362fe87e33fc3afa01f/flask-3.0.0-py3-none-any.whl.metadata\n",
      "  Using cached flask-3.0.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting fonttools==4.43.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 36))\n",
      "  Obtaining dependency information for fonttools==4.43.1 from https://files.pythonhosted.org/packages/ac/ed/9a33eca5e2cc35dc1fea0a968509c653db9a99a5979656ae57c6c019d66b/fonttools-4.43.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached fonttools-4.43.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (152 kB)\n",
      "Collecting frozenlist==1.4.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 37))\n",
      "  Obtaining dependency information for frozenlist==1.4.0 from https://files.pythonhosted.org/packages/1e/28/74b8b6451c89c070d34e753d8b65a1e4ce508a6808b18529f36e8c0e2184/frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting fsspec==2023.10.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 38))\n",
      "  Obtaining dependency information for fsspec==2023.10.0 from https://files.pythonhosted.org/packages/e8/f6/3eccfb530aac90ad1301c582da228e4763f19e719ac8200752a4841b0b2d/fsspec-2023.10.0-py3-none-any.whl.metadata\n",
      "  Using cached fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting gitdb==4.0.11 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 39))\n",
      "  Obtaining dependency information for gitdb==4.0.11 from https://files.pythonhosted.org/packages/fd/5b/8f0c4a5bb9fd491c277c21eff7ccae71b47d43c4446c9d0c6cff2fe8c2c4/gitdb-4.0.11-py3-none-any.whl.metadata\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting GitPython==3.1.40 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 40))\n",
      "  Obtaining dependency information for GitPython==3.1.40 from https://files.pythonhosted.org/packages/8d/c4/82b858fb6483dfb5e338123c154d19c043305b01726a67d89532b8f8f01b/GitPython-3.1.40-py3-none-any.whl.metadata\n",
      "  Using cached GitPython-3.1.40-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting google-auth==2.23.3 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 41))\n",
      "  Obtaining dependency information for google-auth==2.23.3 from https://files.pythonhosted.org/packages/39/7c/2e4fa55a99f83ef9ef229ac5d59c44ceb90e2d0145711590c0fa39669f32/google_auth-2.23.3-py2.py3-none-any.whl.metadata\n",
      "  Using cached google_auth-2.23.3-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-auth-oauthlib==1.1.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 42))\n",
      "  Obtaining dependency information for google-auth-oauthlib==1.1.0 from https://files.pythonhosted.org/packages/ce/33/a907b4b67245647746dde8d61e1643ef5d210c88e090d491efd89eff9f95/google_auth_oauthlib-1.1.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached google_auth_oauthlib-1.1.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting gradio_client==0.3.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 43))\n",
      "  Obtaining dependency information for gradio_client==0.3.0 from https://files.pythonhosted.org/packages/54/3c/cd83b81c6e490c5d4cc2250e5e4089f708c47b0ab17874003aef3da4926c/gradio_client-0.3.0-py3-none-any.whl.metadata\n",
      "  Using cached gradio_client-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting greenlet==3.0.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 44))\n",
      "  Obtaining dependency information for greenlet==3.0.1 from https://files.pythonhosted.org/packages/da/ab/7cc6502628565d70dce2edb619d87554d65ac4e2f17c805a5a45bfaefa5c/greenlet-3.0.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata\n",
      "  Using cached greenlet-3.0.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting grpcio==1.59.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 45))\n",
      "  Obtaining dependency information for grpcio==1.59.0 from https://files.pythonhosted.org/packages/20/7f/e76618521aa9d33c6c1c9c3473f866da521678aa6ea2f4df3a896757748c/grpcio-1.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached grpcio-1.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting gunicorn==21.2.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 46))\n",
      "  Obtaining dependency information for gunicorn==21.2.0 from https://files.pythonhosted.org/packages/0e/2a/c3a878eccb100ccddf45c50b6b8db8cf3301a6adede6e31d48e8531cab13/gunicorn-21.2.0-py3-none-any.whl.metadata\n",
      "  Using cached gunicorn-21.2.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting h11==0.14.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 47))\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting h2o-authn==1.1.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 48))\n",
      "  Obtaining dependency information for h2o-authn==1.1.0 from https://files.pythonhosted.org/packages/c7/6d/0d89889d8579ddb5019c243ad869511887d8043d6f1218d16fc15f2315b5/h2o_authn-1.1.0-py3-none-any.whl.metadata\n",
      "  Using cached h2o_authn-1.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting h2o-mlops==0.62.1a1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 49))\n",
      "  Obtaining dependency information for h2o-mlops==0.62.1a1 from https://files.pythonhosted.org/packages/28/1d/b2e8dd6cbc447280286cb5e03169fa2bc7a4c69433787ab08d0fe3707c2f/h2o_mlops-0.62.1a1-py3-none-any.whl.metadata\n",
      "  Using cached h2o_mlops-0.62.1a1-py3-none-any.whl.metadata (658 bytes)\n",
      "Collecting h2o-wave==1.0.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 50))\n",
      "  Obtaining dependency information for h2o-wave==1.0.0 from https://files.pythonhosted.org/packages/bb/9c/df5a50dc39f9ff95e3d1720ec1a1093f1efb6d6e59c76857e60fa88b06fd/h2o_wave-1.0.0-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Using cached h2o_wave-1.0.0-py3-none-manylinux1_x86_64.whl.metadata (2.9 kB)\n",
      "Collecting h2ogpte==0.9.2 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 51))\n",
      "  Obtaining dependency information for h2ogpte==0.9.2 from https://files.pythonhosted.org/packages/84/9a/faff462d5a008d88fb3be54e2df1ee0aca4c166ec3d27e4423975550e89e/h2ogpte-0.9.2-py3-none-any.whl.metadata\n",
      "  Using cached h2ogpte-0.9.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpcore==0.16.3 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 52))\n",
      "  Using cached httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
      "Collecting httpx==0.23.3 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 53))\n",
      "  Using cached httpx-0.23.3-py3-none-any.whl (71 kB)\n",
      "Collecting huggingface-hub==0.17.3 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 54))\n",
      "  Obtaining dependency information for huggingface-hub==0.17.3 from https://files.pythonhosted.org/packages/aa/f3/3fc97336a0e90516901befd4f500f08d691034d387406fdbde85bea827cc/huggingface_hub-0.17.3-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting idna==3.4 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 55))\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting inquirer==3.1.3 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 56))\n",
      "  Using cached inquirer-3.1.3-py3-none-any.whl (18 kB)\n",
      "Collecting itsdangerous==2.1.2 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 57))\n",
      "  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting Jinja2==3.1.2 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 58))\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting jmespath==1.0.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 59))\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting joblib==1.3.2 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 60))\n",
      "  Obtaining dependency information for joblib==1.3.2 from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting kiwisolver==1.4.5 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 61))\n",
      "  Obtaining dependency information for kiwisolver==1.4.5 from https://files.pythonhosted.org/packages/6f/40/4ab1fdb57fced80ce5903f04ae1aed7c1d5939dda4fd0c0aa526c12fe28a/kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata\n",
      "  Using cached kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting langchain==0.0.251 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 62))\n",
      "  Obtaining dependency information for langchain==0.0.251 from https://files.pythonhosted.org/packages/80/59/9fe4cffec5617fc5d52e79889173947b2451bf660dc96ef54e2083cdafc4/langchain-0.0.251-py3-none-any.whl.metadata\n",
      "  Using cached langchain-0.0.251-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langsmith==0.0.53 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 63))\n",
      "  Obtaining dependency information for langsmith==0.0.53 from https://files.pythonhosted.org/packages/72/82/b4b652719f72c0c2488de3fd0a9e14bb7ac952064d8171aa9ecc0dfdd8ab/langsmith-0.0.53-py3-none-any.whl.metadata\n",
      "  Using cached langsmith-0.0.53-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting llvmlite==0.41.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 64))\n",
      "  Obtaining dependency information for llvmlite==0.41.1 from https://files.pythonhosted.org/packages/57/7d/ef28d5812f852b93bd2a583d00cdcde56833d31b645ae0eaa7e71eecfb4e/llvmlite-0.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached llvmlite-0.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting lxml==4.9.3 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 65))\n",
      "  Obtaining dependency information for lxml==4.9.3 from https://files.pythonhosted.org/packages/3c/d2/11533f0bc47ff4d828a20cfb702f3453fe714bd5b475fcdc8cec6e6b7dcf/lxml-4.9.3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata\n",
      "  Using cached lxml-4.9.3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting Mako==1.2.4 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 66))\n",
      "  Using cached Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "Collecting Markdown==3.5 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 67))\n",
      "  Obtaining dependency information for Markdown==3.5 from https://files.pythonhosted.org/packages/bb/c1/50caaec6cadc1c6adc8fe351e03bd646d6e4dd17f55fca0f4c8d7ea8d3e9/Markdown-3.5-py3-none-any.whl.metadata\n",
      "  Using cached Markdown-3.5-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting MarkupSafe==2.1.3 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 68))\n",
      "  Obtaining dependency information for MarkupSafe==2.1.3 from https://files.pythonhosted.org/packages/12/b3/d9ed2c0971e1435b8a62354b18d3060b66c8cb1d368399ec0b9baa7c0ee5/MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting marshmallow==3.20.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 69))\n",
      "  Obtaining dependency information for marshmallow==3.20.1 from https://files.pythonhosted.org/packages/ed/3c/cebfdcad015240014ff08b883d1c0c427f2ba45ae8c6572851b6ef136cad/marshmallow-3.20.1-py3-none-any.whl.metadata\n",
      "  Using cached marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting matplotlib==3.8.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 70))\n",
      "  Obtaining dependency information for matplotlib==3.8.0 from https://files.pythonhosted.org/packages/b5/24/aaccf324ce862bb82277e8814d2aebbb2a2c160d04e95aa2b8c9dc3137a9/matplotlib-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached matplotlib-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting mlflow==2.8.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 71))\n",
      "  Obtaining dependency information for mlflow==2.8.0 from https://files.pythonhosted.org/packages/64/4a/514286f441cade293efcdf77c9733d4ea3d50cd67e8b444beca1b9d85572/mlflow-2.8.0-py3-none-any.whl.metadata\n",
      "  Using cached mlflow-2.8.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting mpmath==1.3.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 72))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting multidict==6.0.4 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 73))\n",
      "  Using cached multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "Collecting multiprocess==0.70.15 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 74))\n",
      "  Obtaining dependency information for multiprocess==0.70.15 from https://files.pythonhosted.org/packages/35/a8/36d8d7b3e46b377800d8dec47891cdf05842d1a2366909ae4a0c89fbc5e6/multiprocess-0.70.15-py310-none-any.whl.metadata\n",
      "  Using cached multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting mypy-extensions==1.0.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 75))\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting nemo-toolkit==1.21.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 76))\n",
      "  Obtaining dependency information for nemo-toolkit==1.21.0 from https://files.pythonhosted.org/packages/59/31/58466536a75dc1eff0d38be4b008730526ae36dd9693304a2ecb78d6411f/nemo_toolkit-1.21.0-py3-none-any.whl.metadata\n",
      "  Using cached nemo_toolkit-1.21.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting nemoguardrails==0.5.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 77))\n",
      "  Obtaining dependency information for nemoguardrails==0.5.0 from https://files.pythonhosted.org/packages/28/1a/b34010b4da620648a31a000637736eb2b4e2875c82795b77f9605190ab89/nemoguardrails-0.5.0-py3-none-any.whl.metadata\n",
      "  Using cached nemoguardrails-0.5.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting nest-asyncio==1.5.6 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 78))\n",
      "  Using cached nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
      "Collecting networkx==3.2 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 79))\n",
      "  Obtaining dependency information for networkx==3.2 from https://files.pythonhosted.org/packages/f6/eb/5585c96636bbb2755865c31d83a19dd220ef88e716df4659dacb86e009cc/networkx-3.2-py3-none-any.whl.metadata\n",
      "  Using cached networkx-3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting nltk==3.8.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 80))\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting numba==0.58.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 81))\n",
      "  Obtaining dependency information for numba==0.58.1 from https://files.pythonhosted.org/packages/ed/13/b66627125b35f2987bd9872cf028b5e1e1ffcbc8d1e182ac4e84eed3998f/numba-0.58.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Using cached numba-0.58.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting numexpr==2.8.7 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 82))\n",
      "  Obtaining dependency information for numexpr==2.8.7 from https://files.pythonhosted.org/packages/2d/03/de1341ec86bbdf1e4a7ad34d95af4762be8a3efab01d5f96922f1228da3e/numexpr-2.8.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached numexpr-2.8.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
      "Collecting numpy==1.23.5 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 83))\n",
      "  Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "Collecting oauthlib==3.2.2 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 84))\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting onnx==1.15.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 85))\n",
      "  Obtaining dependency information for onnx==1.15.0 from https://files.pythonhosted.org/packages/e6/74/522f651adbcd4b6d359b1a3e381185f8e1cd0ada8e9a97465a1990855dff/onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting openai==0.28.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 86))\n",
      "  Obtaining dependency information for openai==0.28.1 from https://files.pythonhosted.org/packages/1e/9f/385c25502f437686e4aa715969e5eaf5c2cb5e5ffa7c5cdd52f3c6ae967a/openai-0.28.1-py3-none-any.whl.metadata\n",
      "  Using cached openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting openapi-schema-pydantic==1.2.4 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 87))\n",
      "  Using cached openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
      "Collecting pandas==2.1.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 88))\n",
      "  Obtaining dependency information for pandas==2.1.1 from https://files.pythonhosted.org/packages/2f/0e/3b74e8f7c908082793adafb02753477f653ccd7e189f3ba070757d2d0e65/pandas-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached pandas-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting Pillow==10.1.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 89))\n",
      "  Obtaining dependency information for Pillow==10.1.0 from https://files.pythonhosted.org/packages/e5/b9/5c6ad3241f1ccca4b781dfeddbab2dac4480f95aedc351a0e60c9f4c8aa9/Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata\n",
      "  Using cached Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting portalocker==2.8.2 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 90))\n",
      "  Obtaining dependency information for portalocker==2.8.2 from https://files.pythonhosted.org/packages/17/9e/87671efcca80ba6203811540ed1f9c0462c1609d2281d7b7f53cef05da3d/portalocker-2.8.2-py3-none-any.whl.metadata\n",
      "  Using cached portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting protobuf==4.23.4 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 91))\n",
      "  Obtaining dependency information for protobuf==4.23.4 from https://files.pythonhosted.org/packages/01/cb/445b3e465abdb8042a41957dc8f60c54620dc7540dbcf9b458a921531ca2/protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl.metadata\n",
      "  Using cached protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (540 bytes)\n",
      "Collecting pyarrow==13.0.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 92))\n",
      "  Obtaining dependency information for pyarrow==13.0.0 from https://files.pythonhosted.org/packages/a1/14/4ffed5e85b96f0c0ae9e026f940bf71ac7dfbfbffff9f3fe339e32bfce2c/pyarrow-13.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata\n",
      "  Using cached pyarrow-13.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pyasn1==0.5.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 93))\n",
      "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Collecting pyasn1-modules==0.3.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 94))\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting pydantic==1.10.13 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 95))\n",
      "  Obtaining dependency information for pydantic==1.10.13 from https://files.pythonhosted.org/packages/e0/2f/d6f17f8385d718233bcae893d27525443d41201c938b68a4af3d591a33e4/pydantic-1.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached pydantic-1.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (149 kB)\n",
      "Collecting PyJWT==2.8.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 96))\n",
      "  Obtaining dependency information for PyJWT==2.8.0 from https://files.pythonhosted.org/packages/2b/4f/e04a8067c7c96c364cef7ef73906504e2f40d690811c021e1a1901473a19/PyJWT-2.8.0-py3-none-any.whl.metadata\n",
      "  Using cached PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pyparsing==3.1.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 97))\n",
      "  Obtaining dependency information for pyparsing==3.1.1 from https://files.pythonhosted.org/packages/39/92/8486ede85fcc088f1b3dba4ce92dd29d126fd96b0008ea213167940a2475/pyparsing-3.1.1-py3-none-any.whl.metadata\n",
      "  Using cached pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pyphen==0.14.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 98))\n",
      "  Using cached pyphen-0.14.0-py3-none-any.whl (2.0 MB)\n",
      "Collecting python-dotenv==1.0.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 99))\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting python-editor==1.0.4 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 100))\n",
      "  Using cached python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting pytz==2023.3.post1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 101))\n",
      "  Obtaining dependency information for pytz==2023.3.post1 from https://files.pythonhosted.org/packages/32/4d/aaf7eff5deb402fd9a24a1449a8119f00d74ae9c2efa79f8ef9994261fc2/pytz-2023.3.post1-py2.py3-none-any.whl.metadata\n",
      "  Using cached pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting PyYAML==6.0.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 102))\n",
      "  Obtaining dependency information for PyYAML==6.0.1 from https://files.pythonhosted.org/packages/29/61/bf33c6c85c55bc45a29eee3195848ff2d518d84735eb0e2d8cb42e0d285e/PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting querystring-parser==1.2.4 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 103))\n",
      "  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting readchar==4.0.5 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 104))\n",
      "  Using cached readchar-4.0.5-py3-none-any.whl (8.5 kB)\n",
      "Collecting regex==2023.10.3 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 105))\n",
      "  Obtaining dependency information for regex==2023.10.3 from https://files.pythonhosted.org/packages/8f/3e/4b8b40eb3c80aeaf360f0361d956d129bb3d23b2a3ecbe3a04a8f3bdd6d3/regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests==2.31.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 106))\n",
      "  Obtaining dependency information for requests==2.31.0 from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting requests-oauthlib==1.3.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 107))\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting responses==0.18.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 108))\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting rfc3986==1.5.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 109))\n",
      "  Using cached rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting rouge-score==0.1.2 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 110))\n",
      "  Using cached rouge_score-0.1.2-py3-none-any.whl\n",
      "Collecting rsa==4.9 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 111))\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting ruamel.yaml==0.18.3 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 112))\n",
      "  Obtaining dependency information for ruamel.yaml==0.18.3 from https://files.pythonhosted.org/packages/4b/5d/678d7d15071816cb9a5e015fcd090ddc59a6a195ce8965363313e2044595/ruamel.yaml-0.18.3-py3-none-any.whl.metadata\n",
      "  Using cached ruamel.yaml-0.18.3-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting ruamel.yaml.clib==0.2.8 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 113))\n",
      "  Obtaining dependency information for ruamel.yaml.clib==0.2.8 from https://files.pythonhosted.org/packages/d3/62/c60b034d9a008bbd566eeecf53a5a4c73d191c8de261290db6761802b72d/ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata\n",
      "  Using cached ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting s3fs==2023.10.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 114))\n",
      "  Obtaining dependency information for s3fs==2023.10.0 from https://files.pythonhosted.org/packages/55/d1/7d6279cf80ed186a35a884fa2c22b5423611609bcca9296e47bfed0da27b/s3fs-2023.10.0-py3-none-any.whl.metadata\n",
      "  Using cached s3fs-2023.10.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting sacrebleu==2.3.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 115))\n",
      "  Using cached sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "Collecting safetensors==0.4.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 116))\n",
      "  Obtaining dependency information for safetensors==0.4.0 from https://files.pythonhosted.org/packages/20/4e/878b080dbda92666233ec6f316a53969edcb58eab1aa399a64d0521cf953/safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting scikit-learn==1.3.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 117))\n",
      "  Obtaining dependency information for scikit-learn==1.3.1 from https://files.pythonhosted.org/packages/7d/af/03d3a7d5719d00486c296ddd876e6f07a681bc4e079cb45348d2f261a748/scikit_learn-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached scikit_learn-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy==1.11.3 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 118))\n",
      "  Obtaining dependency information for scipy==1.11.3 from https://files.pythonhosted.org/packages/18/44/7e8d208eb59a8224fcc474415104f13be9b378be8da63f76dfde12ec2b44/scipy-1.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached scipy-1.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting sentence-transformers==2.2.2 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 119))\n",
      "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
      "Collecting sentencepiece==0.1.99 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 120))\n",
      "  Using cached sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Collecting simpleeval==0.9.13 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 121))\n",
      "  Using cached simpleeval-0.9.13-py2.py3-none-any.whl (15 kB)\n",
      "Collecting smmap==5.0.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 122))\n",
      "  Obtaining dependency information for smmap==5.0.1 from https://files.pythonhosted.org/packages/a7/a5/10f97f73544edcdef54409f1d839f6049a0d79df68adbc1ceb24d1aaca42/smmap-5.0.1-py3-none-any.whl.metadata\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting sniffio==1.3.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 123))\n",
      "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting soupsieve==2.5 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 124))\n",
      "  Obtaining dependency information for soupsieve==2.5 from https://files.pythonhosted.org/packages/4c/f3/038b302fdfbe3be7da016777069f26ceefe11a681055ea1f7817546508e3/soupsieve-2.5-py3-none-any.whl.metadata\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting SQLAlchemy==2.0.22 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 125))\n",
      "  Obtaining dependency information for SQLAlchemy==2.0.22 from https://files.pythonhosted.org/packages/26/54/6f2a9b21a9dc921181ae1084c35391c51b57daa11f88c830332a69298a62/SQLAlchemy-2.0.22-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached SQLAlchemy-2.0.22-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.4 kB)\n",
      "Collecting sqlparse==0.4.4 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 126))\n",
      "  Using cached sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "Collecting starlette==0.27.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 127))\n",
      "  Obtaining dependency information for starlette==0.27.0 from https://files.pythonhosted.org/packages/58/f8/e2cca22387965584a409795913b774235752be4176d276714e15e1a58884/starlette-0.27.0-py3-none-any.whl.metadata\n",
      "  Using cached starlette-0.27.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting sympy==1.12 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 128))\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting tabulate==0.9.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 129))\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting tenacity==8.2.3 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 130))\n",
      "  Obtaining dependency information for tenacity==8.2.3 from https://files.pythonhosted.org/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl.metadata\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting tensorboard==2.15.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 131))\n",
      "  Obtaining dependency information for tensorboard==2.15.0 from https://files.pythonhosted.org/packages/69/38/fb2ac9c4c8efbe020ae88f6772be87d51ef18526ac541fc3393786b7c45a/tensorboard-2.15.0-py3-none-any.whl.metadata\n",
      "  Using cached tensorboard-2.15.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorboard-data-server==0.7.2 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 132))\n",
      "  Obtaining dependency information for tensorboard-data-server==0.7.2 from https://files.pythonhosted.org/packages/73/c6/825dab04195756cf8ff2e12698f22513b3db2f64925bdd41671bfb33aaa5/tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting text-unidecode==1.3 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 133))\n",
      "  Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Collecting textstat==0.7.3 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 134))\n",
      "  Using cached textstat-0.7.3-py3-none-any.whl (105 kB)\n",
      "Collecting threadpoolctl==3.2.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 135))\n",
      "  Obtaining dependency information for threadpoolctl==3.2.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Collecting tokenizers==0.14.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 136))\n",
      "  Obtaining dependency information for tokenizers==0.14.1 from https://files.pythonhosted.org/packages/a7/7b/c1f643eb086b6c5c33eef0c3752e37624bd23e4cbc9f1332748f1c6252d1/tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting torch==2.1.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 137))\n",
      "  Obtaining dependency information for torch==2.1.0 from https://files.pythonhosted.org/packages/6d/13/b5e8bacd980b2195f8a1741ce11cbb9146568607795d5e4ff510dcff1064/torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata\n",
      "  Using cached torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting torchvision==0.16.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 138))\n",
      "  Obtaining dependency information for torchvision==0.16.0 from https://files.pythonhosted.org/packages/84/eb/4f6483ae9094e164dc5b9b792e377f7d37823b0bedc3eef3193d416d2bb6/torchvision-0.16.0-cp310-cp310-manylinux1_x86_64.whl.metadata\n",
      "  Using cached torchvision-0.16.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting tqdm==4.66.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 139))\n",
      "  Obtaining dependency information for tqdm==4.66.1 from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting transformers==4.34.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 140))\n",
      "  Obtaining dependency information for transformers==4.34.1 from https://files.pythonhosted.org/packages/c1/bd/f64d67df4d3b05a460f281defe830ffab6d7940b7ca98ec085e94e024781/transformers-4.34.1-py3-none-any.whl.metadata\n",
      "  Using cached transformers-4.34.1-py3-none-any.whl.metadata (121 kB)\n",
      "Collecting typer==0.7.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 141))\n",
      "  Using cached typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting typing-inspect==0.9.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 142))\n",
      "  Obtaining dependency information for typing-inspect==0.9.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting typing_extensions==4.5.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 143))\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting tzdata==2023.3 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 144))\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Collecting urllib3==2.0.7 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 145))\n",
      "  Obtaining dependency information for urllib3==2.0.7 from https://files.pythonhosted.org/packages/d2/b2/b157855192a68541a91ba7b2bbcb91f1b4faa51f8bae38d8005c034be524/urllib3-2.0.7-py3-none-any.whl.metadata\n",
      "  Using cached urllib3-2.0.7-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting uvicorn==0.22.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 146))\n",
      "  Using cached uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
      "Collecting websocket-client==1.6.4 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 147))\n",
      "  Obtaining dependency information for websocket-client==1.6.4 from https://files.pythonhosted.org/packages/c4/3c/1892ce394828c43d4f65248ebdee3854114266b75d1f5915cb211155ad7b/websocket_client-1.6.4-py3-none-any.whl.metadata\n",
      "  Using cached websocket_client-1.6.4-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting websockets==11.0.3 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 148))\n",
      "  Using cached websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Collecting Werkzeug==3.0.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 149))\n",
      "  Obtaining dependency information for Werkzeug==3.0.1 from https://files.pythonhosted.org/packages/c3/fc/254c3e9b5feb89ff5b9076a23218dafbc99c96ac5941e900b71206e6313b/werkzeug-3.0.1-py3-none-any.whl.metadata\n",
      "  Using cached werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting wget==3.2 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 150))\n",
      "  Using cached wget-3.2-py3-none-any.whl\n",
      "Collecting wrapt==1.15.0 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 151))\n",
      "  Using cached wrapt-1.15.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
      "Collecting xxhash==3.4.1 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 152))\n",
      "  Obtaining dependency information for xxhash==3.4.1 from https://files.pythonhosted.org/packages/80/8a/1dd41557883b6196f8f092011a5c1f72d4d44cf36d7b67d4a5efe3127949/xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl==1.9.2 (from -r /kaggle/input/requirements/requirements_lab1.txt (line 153))\n",
      "  Using cached yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "Collecting profanity_check (from -r /kaggle/input/requirements/requirements_lab1.txt (line 154))\n",
      "  Using cached profanity_check-1.0.3-py3-none-any.whl (2.4 MB)\n",
      "Collecting packaging>=20.0 (from accelerate==0.24.0->-r /kaggle/input/requirements/requirements_lab1.txt (line 2))\n",
      "  Obtaining dependency information for packaging>=20.0 from https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl.metadata\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting psutil (from accelerate==0.24.0->-r /kaggle/input/requirements/requirements_lab1.txt (line 2))\n",
      "  Obtaining dependency information for psutil from https://files.pythonhosted.org/packages/19/06/4e3fa3c1b79271e933c5ddbad3a48aa2c3d5f592a0fb7c037f3e0f619f4d/psutil-5.9.6-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached psutil-5.9.6-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting exceptiongroup>=1.0.2 (from anyio==4.0.0->-r /kaggle/input/requirements/requirements_lab1.txt (line 10))\n",
      "  Obtaining dependency information for exceptiongroup>=1.0.2 from https://files.pythonhosted.org/packages/ad/83/b71e58666f156a39fb29417e4c8ca4bc7400c0dd4ed9e8842ab54dc8c344/exceptiongroup-1.1.3-py3-none-any.whl.metadata\n",
      "  Using cached exceptiongroup-1.1.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting wcwidth>=0.1.4 (from blessed==1.20.0->-r /kaggle/input/requirements/requirements_lab1.txt (line 14))\n",
      "  Obtaining dependency information for wcwidth>=0.1.4 from https://files.pythonhosted.org/packages/19/0b/00728863778b14ececfc97e40850fd71529b6a1695907981cc3fdc085ba6/wcwidth-0.2.9-py2.py3-none-any.whl.metadata\n",
      "  Using cached wcwidth-0.2.9-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting six>=1.9.0 (from blessed==1.20.0->-r /kaggle/input/requirements/requirements_lab1.txt (line 14))\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting python-dateutil<3.0.0,>=2.1 (from botocore==1.31.64->-r /kaggle/input/requirements/requirements_lab1.txt (line 16))\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting importlib-metadata!=4.7.0,<7,>=3.7.0 (from mlflow==2.8.0->-r /kaggle/input/requirements/requirements_lab1.txt (line 71))\n",
      "  Obtaining dependency information for importlib-metadata!=4.7.0,<7,>=3.7.0 from https://files.pythonhosted.org/packages/cc/37/db7ba97e676af155f5fcb1a35466f446eadc9104e25b83366e8088c9c926/importlib_metadata-6.8.0-py3-none-any.whl.metadata\n",
      "  Using cached importlib_metadata-6.8.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting setuptools>=65.5.1 (from nemo-toolkit==1.21.0->-r /kaggle/input/requirements/requirements_lab1.txt (line 76))\n",
      "  Obtaining dependency information for setuptools>=65.5.1 from https://files.pythonhosted.org/packages/bb/26/7945080113158354380a12ce26873dd6c1ebd88d47f5bc24e2c5bb38c16a/setuptools-68.2.2-py3-none-any.whl.metadata\n",
      "  Using cached setuptools-68.2.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "  Using cached setuptools-65.5.1-py3-none-any.whl (1.2 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.0->-r /kaggle/input/requirements/requirements_lab1.txt (line 137))\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.0->-r /kaggle/input/requirements/requirements_lab1.txt (line 137))\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.0->-r /kaggle/input/requirements/requirements_lab1.txt (line 137))\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.0->-r /kaggle/input/requirements/requirements_lab1.txt (line 137))\n",
      "  Obtaining dependency information for nvidia-cudnn-cu12==8.9.2.26 from https://files.pythonhosted.org/packages/ff/74/a2e2be7fb83aaedec84f391f082cf765dfb635e7caa9b49065f73e4835d8/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.0->-r /kaggle/input/requirements/requirements_lab1.txt (line 137))\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.0->-r /kaggle/input/requirements/requirements_lab1.txt (line 137))\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.0->-r /kaggle/input/requirements/requirements_lab1.txt (line 137))\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.0->-r /kaggle/input/requirements/requirements_lab1.txt (line 137))\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.0->-r /kaggle/input/requirements/requirements_lab1.txt (line 137))\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.0->-r /kaggle/input/requirements/requirements_lab1.txt (line 137))\n",
      "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.0->-r /kaggle/input/requirements/requirements_lab1.txt (line 137))\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==2.1.0 (from torch==2.1.0->-r /kaggle/input/requirements/requirements_lab1.txt (line 137))\n",
      "  Obtaining dependency information for triton==2.1.0 from https://files.pythonhosted.org/packages/4d/22/91a8af421c8a8902dde76e6ef3db01b258af16c53d81e8c0d0dc13900a9e/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->-r /kaggle/input/requirements/requirements_lab1.txt (line 137))\n",
      "  Obtaining dependency information for nvidia-nvjitlink-cu12 from https://files.pythonhosted.org/packages/45/de/885b6d3e1fa07bf19124076b348d3cf30f68051f813cba99e103f53d2f75/nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Using cached nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow==2.8.0->-r /kaggle/input/requirements/requirements_lab1.txt (line 71))\n",
      "  Obtaining dependency information for zipp>=0.5 from https://files.pythonhosted.org/packages/d9/66/48866fc6b158c81cc2bfecc04c480f105c6040e8b077bc54c634b4a67926/zipp-3.17.0-py3-none-any.whl.metadata\n",
      "  Using cached zipp-3.17.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Using cached absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "Using cached accelerate-0.24.0-py3-none-any.whl (260 kB)\n",
      "Using cached aiobotocore-2.7.0-py3-none-any.whl (73 kB)\n",
      "Using cached aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "Using cached alembic-1.12.1-py3-none-any.whl (226 kB)\n",
      "Using cached anyio-4.0.0-py3-none-any.whl (83 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached blinker-1.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached botocore-1.31.64-py3-none-any.whl (11.3 MB)\n",
      "Using cached cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Using cached certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "Using cached charset_normalizer-3.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached contourpy-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached databricks_cli-0.18.0-py2.py3-none-any.whl (150 kB)\n",
      "Using cached dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
      "Using cached datasets-2.14.6-py3-none-any.whl (493 kB)\n",
      "Using cached dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "Using cached docker-6.1.3-py3-none-any.whl (148 kB)\n",
      "Using cached evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "Using cached fastapi-0.96.0-py3-none-any.whl (57 kB)\n",
      "Using cached filelock-3.12.4-py3-none-any.whl (11 kB)\n",
      "Using cached flask-3.0.0-py3-none-any.whl (99 kB)\n",
      "Using cached fonttools-4.43.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "Using cached frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
      "Using cached fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Using cached GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
      "Using cached google_auth-2.23.3-py2.py3-none-any.whl (182 kB)\n",
      "Using cached google_auth_oauthlib-1.1.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached gradio_client-0.3.0-py3-none-any.whl (294 kB)\n",
      "Using cached greenlet-3.0.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (613 kB)\n",
      "Using cached grpcio-1.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "Using cached gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
      "Using cached h2o_authn-1.1.0-py3-none-any.whl (12 kB)\n",
      "Using cached h2o_mlops-0.62.1a1-py3-none-any.whl (771 kB)\n",
      "Using cached h2o_wave-1.0.0-py3-none-manylinux1_x86_64.whl (12.1 MB)\n",
      "Using cached h2ogpte-0.9.2-py3-none-any.whl (7.8 kB)\n",
      "Using cached huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Using cached langchain-0.0.251-py3-none-any.whl (1.4 MB)\n",
      "Using cached langsmith-0.0.53-py3-none-any.whl (43 kB)\n",
      "Using cached llvmlite-0.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "Using cached lxml-4.9.3-cp310-cp310-manylinux_2_28_x86_64.whl (7.9 MB)\n",
      "Using cached Markdown-3.5-py3-none-any.whl (101 kB)\n",
      "Using cached MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Using cached marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "Using cached matplotlib-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "Using cached mlflow-2.8.0-py3-none-any.whl (19.0 MB)\n",
      "Using cached multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "Using cached nemo_toolkit-1.21.0-py3-none-any.whl (2.5 MB)\n",
      "Using cached nemoguardrails-0.5.0-py3-none-any.whl (13.9 MB)\n",
      "Using cached networkx-3.2-py3-none-any.whl (1.6 MB)\n",
      "Using cached numba-0.58.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
      "Using cached numexpr-2.8.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (384 kB)\n",
      "Using cached onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
      "Using cached openai-0.28.1-py3-none-any.whl (76 kB)\n",
      "Using cached pandas-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "Using cached Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "Using cached portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Using cached protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "Using cached pyarrow-13.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.0 MB)\n",
      "Using cached pydantic-1.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Using cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
      "Using cached regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached ruamel.yaml-0.18.3-py3-none-any.whl (114 kB)\n",
      "Using cached ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
      "Using cached s3fs-2023.10.0-py3-none-any.whl (28 kB)\n",
      "Using cached safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached scikit_learn-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "Using cached scipy-1.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
      "Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Using cached SQLAlchemy-2.0.22-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached tensorboard-2.15.0-py3-none-any.whl (5.6 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Using cached tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "Using cached torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "Using cached torchvision-0.16.0-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Using cached transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
      "Using cached websocket_client-1.6.4-py3-none-any.whl (57 kB)\n",
      "Using cached werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "Using cached xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "Using cached exceptiongroup-1.1.3-py3-none-any.whl (14 kB)\n",
      "Using cached importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Using cached psutil-5.9.6-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
      "Using cached wcwidth-0.2.9-py2.py3-none-any.whl (102 kB)\n",
      "Using cached zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "Installing collected packages: wget, wcwidth, text-unidecode, simpleeval, sentencepiece, rfc3986, pytz, python-editor, mpmath, annoy, zipp, xxhash, wrapt, websockets, websocket-client, urllib3, tzdata, typing_extensions, tqdm, threadpoolctl, tensorboard-data-server, tenacity, tabulate, sympy, sqlparse, soupsieve, sniffio, smmap, six, setuptools, safetensors, ruamel.yaml.clib, regex, PyYAML, python-dotenv, pyphen, pyparsing, PyJWT, pyasn1, psutil, protobuf, portalocker, Pillow, packaging, oauthlib, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, nest-asyncio, mypy-extensions, multidict, MarkupSafe, Markdown, lxml, llvmlite, kiwisolver, joblib, jmespath, itsdangerous, idna, h11, grpcio, greenlet, fsspec, frozenlist, fonttools, filelock, exceptiongroup, entrypoints, dill, cycler, colorama, cloudpickle, click, charset-normalizer, certifi, cachetools, blinker, attrs, async-timeout, aioitertools, absl-py, yarl, Werkzeug, uvicorn, typing-inspect, typer, triton, textstat, SQLAlchemy, scipy, sacrebleu, ruamel.yaml, rsa, requests, readchar, querystring-parser, python-dateutil, pydantic, pyasn1-modules, pyarrow, onnx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numexpr, numba, nltk, multiprocess, marshmallow, Mako, Jinja2, importlib-metadata, gunicorn, gitdb, contourpy, blessed, beautifulsoup4, anyio, aiosignal, starlette, scikit-learn, rouge-score, responses, requests-oauthlib, pandas, openapi-schema-pydantic, nvidia-cusolver-cu12, matplotlib, langsmith, inquirer, huggingface-hub, httpcore, google-auth, GitPython, Flask, docker, dataclasses-json, databricks-cli, bs4, botocore, alembic, aiohttp, torch, tokenizers, profanity_check, openai, mlflow, langchain, httpx, h2ogpte, google-auth-oauthlib, fastapi, alt-profanity-check, aiobotocore, transformers, torchvision, tensorboard, s3fs, h2o-wave, h2o-authn, gradio_client, datasets, accelerate, sentence-transformers, nemo-toolkit, h2o-mlops, evaluate, nemoguardrails\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\n",
      "apache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.23.4 which is incompatible.\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 13.0.0 which is incompatible.\n",
      "beatrix-jupyterlab 2023.814.150030 requires jupyter-server~=1.16, but you have jupyter-server 2.9.1 which is incompatible.\n",
      "beatrix-jupyterlab 2023.814.150030 requires jupyterlab~=3.4, but you have jupyterlab 4.0.5 which is incompatible.\n",
      "boto3 1.26.100 requires botocore<1.30.0,>=1.29.100, but you have botocore 1.31.64 which is incompatible.\n",
      "chex 0.1.84 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
      "conda 23.7.4 requires ruamel-yaml<0.18,>=0.11.14, but you have ruamel-yaml 0.18.3 which is incompatible.\n",
      "cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.1 which is incompatible.\n",
      "cudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 13.0.0 which is incompatible.\n",
      "cuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.10.1 which is incompatible.\n",
      "cuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.10.1 which is incompatible.\n",
      "dask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.10.1 which is incompatible.\n",
      "dask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.10.1 which is incompatible.\n",
      "dask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.1 which is incompatible.\n",
      "dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.10.1 which is incompatible.\n",
      "dask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.10.1 which is incompatible.\n",
      "dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.1 which is incompatible.\n",
      "gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.10.0 which is incompatible.\n",
      "google-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\n",
      "google-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\n",
      "google-cloud-bigquery 2.34.4 requires protobuf<4.0.0dev,>=3.12.0, but you have protobuf 4.23.4 which is incompatible.\n",
      "google-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.23.4 which is incompatible.\n",
      "google-cloud-vision 2.8.0 requires protobuf<4.0.0dev,>=3.19.0, but you have protobuf 4.23.4 which is incompatible.\n",
      "jupyterlab 4.0.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "jupyterlab-lsp 5.0.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "jupyterlab-lsp 5.0.0 requires jupyterlab<5.0.0a0,>=4.0.6, but you have jupyterlab 4.0.5 which is incompatible.\n",
      "kfp 2.0.1 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\n",
      "kfp 2.0.1 requires protobuf<4,>=3.13.0, but you have protobuf 4.23.4 which is incompatible.\n",
      "kfp 2.0.1 requires urllib3<2.0.0, but you have urllib3 2.0.7 which is incompatible.\n",
      "kfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.23.4 which is incompatible.\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "momepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "pins 0.8.3 requires fsspec<2023.9.0,>=0.8.0, but you have fsspec 2023.10.0 which is incompatible.\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\n",
      "pydantic-core 2.10.1 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "pymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\n",
      "pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.3 which is incompatible.\n",
      "raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.10.1 which is incompatible.\n",
      "raft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.10.1 which is incompatible.\n",
      "tensorflow 2.13.0 requires tensorboard<2.14,>=2.13, but you have tensorboard 2.15.0 which is incompatible.\n",
      "tensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.23.4 which is incompatible.\n",
      "tensorflow-transform 0.14.0 requires absl-py<2,>=0.7, but you have absl-py 2.0.0 which is incompatible.\n",
      "tensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.23.4 which is incompatible.\n",
      "torchdata 0.6.0 requires torch==2.0.0, but you have torch 2.1.0 which is incompatible.\n",
      "ydata-profiling 4.5.1 requires pandas!=1.4.0,<2.1,>1.1, but you have pandas 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Flask-3.0.0 GitPython-3.1.40 Jinja2-3.1.2 Mako-1.2.4 Markdown-3.5 MarkupSafe-2.1.3 Pillow-10.1.0 PyJWT-2.8.0 PyYAML-6.0.1 SQLAlchemy-2.0.22 Werkzeug-3.0.1 absl-py-2.0.0 accelerate-0.24.0 aiobotocore-2.7.0 aiohttp-3.8.5 aioitertools-0.11.0 aiosignal-1.3.1 alembic-1.12.1 alt-profanity-check-1.3.1 annoy-1.17.3 anyio-4.0.0 async-timeout-4.0.3 attrs-23.1.0 beautifulsoup4-4.12.2 blessed-1.20.0 blinker-1.7.0 botocore-1.31.64 bs4-0.0.1 cachetools-5.3.2 certifi-2023.7.22 charset-normalizer-3.3.1 click-8.1.7 cloudpickle-2.2.1 colorama-0.4.6 contourpy-1.1.1 cycler-0.12.1 databricks-cli-0.18.0 dataclasses-json-0.5.14 datasets-2.14.6 dill-0.3.7 docker-6.1.3 entrypoints-0.4 evaluate-0.4.1 exceptiongroup-1.1.3 fastapi-0.96.0 filelock-3.12.4 fonttools-4.43.1 frozenlist-1.4.0 fsspec-2023.10.0 gitdb-4.0.11 google-auth-2.23.3 google-auth-oauthlib-1.1.0 gradio_client-0.3.0 greenlet-3.0.1 grpcio-1.59.0 gunicorn-21.2.0 h11-0.14.0 h2o-authn-1.1.0 h2o-mlops-0.62.1a1 h2o-wave-1.0.0 h2ogpte-0.9.2 httpcore-0.16.3 httpx-0.23.3 huggingface-hub-0.17.3 idna-3.4 importlib-metadata-6.8.0 inquirer-3.1.3 itsdangerous-2.1.2 jmespath-1.0.1 joblib-1.3.2 kiwisolver-1.4.5 langchain-0.0.251 langsmith-0.0.53 llvmlite-0.41.1 lxml-4.9.3 marshmallow-3.20.1 matplotlib-3.8.0 mlflow-2.8.0 mpmath-1.3.0 multidict-6.0.4 multiprocess-0.70.15 mypy-extensions-1.0.0 nemo-toolkit-1.21.0 nemoguardrails-0.5.0 nest-asyncio-1.5.6 networkx-3.2 nltk-3.8.1 numba-0.58.1 numexpr-2.8.7 numpy-1.23.5 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.52 nvidia-nvtx-cu12-12.1.105 oauthlib-3.2.2 onnx-1.15.0 openai-0.28.1 openapi-schema-pydantic-1.2.4 packaging-23.2 pandas-2.1.1 portalocker-2.8.2 profanity_check-1.0.3 protobuf-4.23.4 psutil-5.9.6 pyarrow-13.0.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 pydantic-1.10.13 pyparsing-3.1.1 pyphen-0.14.0 python-dateutil-2.8.2 python-dotenv-1.0.0 python-editor-1.0.4 pytz-2023.3.post1 querystring-parser-1.2.4 readchar-4.0.5 regex-2023.10.3 requests-2.31.0 requests-oauthlib-1.3.1 responses-0.18.0 rfc3986-1.5.0 rouge-score-0.1.2 rsa-4.9 ruamel.yaml-0.18.3 ruamel.yaml.clib-0.2.8 s3fs-2023.10.0 sacrebleu-2.3.1 safetensors-0.4.0 scikit-learn-1.3.1 scipy-1.11.3 sentence-transformers-2.2.2 sentencepiece-0.1.99 setuptools-65.5.1 simpleeval-0.9.13 six-1.16.0 smmap-5.0.1 sniffio-1.3.0 soupsieve-2.5 sqlparse-0.4.4 starlette-0.27.0 sympy-1.12 tabulate-0.9.0 tenacity-8.2.3 tensorboard-2.15.0 tensorboard-data-server-0.7.2 text-unidecode-1.3 textstat-0.7.3 threadpoolctl-3.2.0 tokenizers-0.14.1 torch-2.1.0 torchvision-0.16.0 tqdm-4.66.1 transformers-4.34.1 triton-2.1.0 typer-0.7.0 typing-inspect-0.9.0 typing_extensions-4.5.0 tzdata-2023.3 urllib3-2.0.7 uvicorn-0.22.0 wcwidth-0.2.9 websocket-client-1.6.4 websockets-11.0.3 wget-3.2 wrapt-1.15.0 xxhash-3.4.1 yarl-1.9.2 zipp-3.17.0\n",
      "\u001b[33mWARNING: Target directory /kaggle/working/workshop/rouge_score-0.1.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/scipy-1.11.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/profanity_check already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/zipp-3.17.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/inquirer already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/torch-2.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/_multiprocess already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/readchar-4.0.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/h11-0.14.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/python_dateutil-2.8.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/idna-3.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/rouge_score already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/datasets already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/numba already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/anyio-4.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/sympy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/pytz already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/dataclasses_json already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/pydantic-1.10.13.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/text_unidecode already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/PyJWT-2.8.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/accelerate-0.24.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/botocore already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/httpx already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/cachetools already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/cycler already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/h11 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/pylint_plugins already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/Pillow-10.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/evaluate already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/networkx-3.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/fsspec-2023.10.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/joblib already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/mpmath already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/databricks_cli-0.18.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/absl already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/h2o_wave already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/blinker-1.7.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/isympy.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/mlflow already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/psutil-5.9.6.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/fastapi already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/openapi_schema_pydantic-1.2.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/kiwisolver already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/mypy_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/setuptools already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/MarkupSafe-2.1.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/multidict-6.0.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/h2o_mlops already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/starlette-0.27.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/pyphen-0.14.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/sentence_transformers-2.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/httpcore already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/greenlet already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/transformers-4.34.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/tzdata-2023.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/triton already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/packaging-23.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/sqlparse-0.4.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/oauthlib already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/joblib-1.3.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/numpy-1.23.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/pyasn1 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/dateutil already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/pyparsing-3.1.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/SQLAlchemy-2.0.22.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/h2ogpte already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/langsmith already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/pydantic already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/cloudpickle already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/torchgen already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/nest_asyncio-1.5.6.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/scipy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/attrs-23.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/importlib_metadata-6.8.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/mpl_toolkits already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/greenlet-3.0.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/certifi-2023.7.22.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/entrypoints-0.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/nvidia_cuda_cupti_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/annoy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/Pillow.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/google_auth-2.23.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/pytz-2023.3.post1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/dotenv already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/oauthlib-3.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/attr already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/dill already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/starlette already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/cycler-0.12.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/nvidia_nvtx_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/regex-2023.10.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/openapi_schema_pydantic already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/fastapi-0.96.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/smmap-5.0.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/nvidia_nccl_cu12-2.18.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/tokenizers-0.14.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/nemoguardrails-0.5.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/nest_asyncio.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/wget.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/marshmallow-3.20.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/textstat-0.7.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/portalocker already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/frozenlist-1.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/matplotlib already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/tqdm already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/responses already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/wrapt-1.15.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/botocore-1.31.64.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/typer-0.7.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/pyasn1-0.5.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/nvidia_cuda_nvrtc_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/wcwidth already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/networkx already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/torch already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/google_auth_oauthlib already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/nvfuser already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/responses-0.18.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/scikit_learn.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/click already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/importlib_metadata already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/h2o_authn-1.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/qa already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/tests already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/httpcore-0.16.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/nemo already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/colorama already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/sniffio-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/onnx-1.15.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/pylab.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/onnx already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/portalocker-2.8.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/torchvision.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/tenacity already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/typing_extensions-4.5.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/nvidia_nvjitlink_cu12-12.3.52.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/attrs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/jmespath already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/openai-0.28.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/cloudpickle-2.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/jinja2 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/blessed-1.20.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/PIL already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/s3fs-2023.10.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/profanity_check-1.0.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/fonttools-4.43.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/jwt already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/_yaml already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/six.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/contourpy-1.1.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/wget-3.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/simpleeval-0.9.13.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/async_timeout-4.0.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/typing_inspect-0.9.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/google_auth_oauthlib-1.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/numba-0.58.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/llvmlite-0.41.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/multiprocess-0.70.15.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/transformers already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/tqdm-4.66.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/typing_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/websocket_client-1.6.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/soupsieve already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/sqlalchemy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/jmespath-1.0.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/google already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/sklearn already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/yarl already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/bs4 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/uvicorn already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/anyio already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/readchar already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/pyarrow-13.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/nemoguardrails already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/evaluate-0.4.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/scikit_learn-1.3.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/accelerate already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/nltk already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/regex already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/xxhash already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/functorch already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/examples already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/aioitertools already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/alembic already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/rfc3986 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/mako already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/nvidia already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/pyasn1_modules already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/h2o_wave-1.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/huggingface_hub already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/charset_normalizer already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/docker already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/alembic-1.12.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/itsdangerous already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/rfc3986-1.5.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/entrypoints.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/exceptiongroup-1.1.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/flask already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/numexpr already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/charset_normalizer-3.3.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/multidict already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/aiohttp already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/sqlparse already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/editor.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/simpleeval.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/python_editor-1.0.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/h2o_authn already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/async_timeout already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/threadpoolctl.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/colorama-0.4.6.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/requests_oauthlib-1.3.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/markupsafe already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/tabulate-0.9.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/ruamel already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/tensorboard-2.15.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/pyasn1_modules-0.3.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/idna already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/nvidia_cudnn_cu12-8.9.2.26.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/triton-2.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/docker-6.1.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/nvidia_cuda_runtime_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/_ruamel_yaml.cpython-310-x86_64-linux-gnu.so already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/pyarrow already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/aiobotocore already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/pyparsing already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/llvmlite already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/certifi already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/bs4-0.0.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/text_unidecode-1.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/annoy-1.17.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/numexpr-2.8.7.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/matplotlib-3.8.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/beautifulsoup4-4.12.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/websocket already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/soupsieve-2.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/lxml-4.9.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/GitPython-3.1.40.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/gitdb-4.0.11.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/setuptools-65.5.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/Jinja2-3.1.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/sacrebleu already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/filelock-3.12.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/sympy-1.12.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/huggingface_hub-0.17.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/kiwisolver-1.4.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/safetensors-0.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/exceptiongroup already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/openai already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/tensorboard already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/aioitertools-0.11.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/fsspec already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/frozenlist already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/nemo_toolkit-1.21.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/torchvision-0.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/safetensors already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/xxhash-3.4.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/querystring_parser already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/sniffio already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/marshmallow already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/yaml already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/langchain-0.0.251.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/pandas-2.1.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/werkzeug already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/typer already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/sacrebleu-2.3.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/tokenizers already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/gitdb already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/uvicorn-0.22.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/tensorboard_data_server already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/sentencepiece-0.1.99.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/langchain already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/multiprocess already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/scipy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/tenacity-8.2.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/pandas already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/pkg_resources already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/inquirer-3.1.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/requests_oauthlib already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/werkzeug-3.0.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/aiosignal already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/wrapt already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/sentence_transformers already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/nvidia_cublas_cu12-12.1.3.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/sentencepiece already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/aiohttp-3.8.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/_distutils_hack already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/textstat already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/wcwidth-0.2.9.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/urllib3-2.0.7.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/Mako-1.2.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/gunicorn-21.2.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/packaging already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/PyYAML-6.0.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/requests already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/mypy_extensions-1.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/blessed already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/nltk-3.8.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/aiobotocore-2.7.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/s3fs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/tzdata already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/six-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/grpcio-1.59.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/Markdown-3.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/markdown already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/nvidia_curand_cu12-10.3.2.106.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/distutils-precedence.pth already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/nvidia_cufft_cu12-11.0.2.54.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/pyphen already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/contourpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/httpx-0.23.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/tabulate already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/itsdangerous-2.1.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/rsa already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/h2ogpte-0.9.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/click-8.1.7.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/nvidia_cusolver_cu12-11.4.5.107.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/cachetools-5.3.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/gunicorn already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/protobuf-4.23.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/databricks_cli already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/python_dotenv-1.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/dill-0.3.7.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/datasets-2.14.6.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/querystring_parser-1.2.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/psutil already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/alt_profanity_check-1.3.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/flask-3.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/lxml already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/gradio_client-0.3.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/requests-2.31.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/mlflow-2.8.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/chat-ui already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/zipp already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/yarl-1.9.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/dataclasses_json-0.5.14.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/ruamel.yaml.clib-0.2.8.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/git already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/tensorboard_data_server-0.7.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/torchvision already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/nvidia_cusparse_cu12-12.1.0.106.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/aiosignal-1.3.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/profanity-check already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/threadpoolctl-3.2.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/h2o_mlops-0.62.1a1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/fontTools already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/ruamel.yaml-0.18.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/gradio_client already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/grpc already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/smmap already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/websockets already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/filelock already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/absl_py-2.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/websockets-11.0.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/langsmith-0.0.53.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/typing_inspect.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/rsa-4.9.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/blinker already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/readme.txt already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/waved already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/include already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/www already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/project_templates already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /kaggle/working/workshop/share already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements_lab1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cecdfe",
   "metadata": {},
   "source": [
    "# Setup and List Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6c5c380",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T20:01:12.627886Z",
     "iopub.status.busy": "2023-11-10T20:01:12.627144Z",
     "iopub.status.idle": "2023-11-10T20:01:17.380721Z",
     "shell.execute_reply": "2023-11-10T20:01:17.379672Z",
     "shell.execute_reply.started": "2023-11-10T20:01:12.627844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://gpt-genai.h2o.ai/ \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'h2oai/h2ogpt-4096-llama2-70b-chat': 4046,\n",
       " 'h2oai/h2ogpt-4096-llama2-13b-chat': 4046,\n",
       " 'HuggingFaceH4/zephyr-7b-beta': 8142,\n",
       " 'gpt-3.5-turbo-0613': 4046,\n",
       " 'lmsys/vicuna-13b-v1.5-16k': 16334,\n",
       " 'h2oai/h2ogpt-4096-llama2-70b-chat-4bit': 4046,\n",
       " 'Yukang/LongAlpaca-70B': 32718,\n",
       " 'h2oai/h2ogpt-32k-codellama-34b-instruct': 32718,\n",
       " 'gpt-3.5-turbo-16k-0613': 16335,\n",
       " 'gpt-4-0613': 8142,\n",
       " 'gpt-4-32k-0613': 32718}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from gradio_client import Client\n",
    "import ast\n",
    "import json\n",
    "\n",
    "# Public h2oGPT\n",
    "HOST_URL = \"https://gpt-genai.h2o.ai/\"\n",
    "H2OGPT_KEY = \"f74f043e-45fc-4dfe-9c33-55a4720427f6\"\n",
    "    \n",
    "client = Client(HOST_URL)\n",
    "\n",
    "# List Models\n",
    "res = client.predict(api_name='/model_names')\n",
    "{x['base_model']: x['max_seq_len'] for x in ast.literal_eval(res)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbfa955",
   "metadata": {},
   "source": [
    "# Competing Models\n",
    "\n",
    "For this example, we will take at two separate models:\n",
    "\n",
    "- `Vicuna 13B`\n",
    "- `Llama2 13B`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de59821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_a = 'h2oai/h2ogpt-4096-llama2-13b-chat'\n",
    "model_b = 'lmsys/vicuna-13b-v1.5-16k'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a0702c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"  My name is LLaMA, I'm a large language model trained by a team of \"\n",
      "\n",
      " 'researcher at Meta AI. My purpose is to assist and converse with humans in a '\n",
      "\n",
      " 'helpful and informative manner. I am capable of answering questions, '\n",
      "\n",
      " 'providing information, and engaging in conversation on a wide range of '\n",
      "\n",
      " 'topics. I am constantly learning and improving my abilities, so please bear '\n",
      "\n",
      " \"with me if I make any mistakes or don't understand your question at first. \"\n",
      "\n",
      " \"I'm here to help!\")\n",
      "\n",
      "-------\n",
      "\n",
      "(\" My name is Vicuna, and I'm a language model developed by Large Model \"\n",
      "\n",
      " 'Systems Organization (LMSYS).')\n"
     ]
    }
   ],
   "source": [
    "# helper function\n",
    "def query_llm(query, model):\n",
    "    '''Function to query a large language model hosting at h2oGPT'''\n",
    "    \n",
    "    # string of dict for input, add h2ogpt_key\n",
    "    kwargs = dict(\n",
    "        instruction_nochat=query, \n",
    "        visible_models=[model], \n",
    "        h2ogpt_key = H2OGPT_KEY)\n",
    "\n",
    "    response = client.predict(str(dict(kwargs)), api_name='/submit_nochat_api')\n",
    "    results = ast.literal_eval(response)\n",
    "    return results\n",
    "\n",
    "query = \"What is your name?\"\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "# Who is Model A?\n",
    "pp.pprint(query_llm(query, model_a)['response'])\n",
    "\n",
    "print(\"-------\")\n",
    "\n",
    "# Who is Model B?\n",
    "pp.pprint(query_llm(query, model_b)['response'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1270167c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>headline</th>\n",
       "      <th>about</th>\n",
       "      <th>content</th>\n",
       "      <th>reactions</th>\n",
       "      <th>profanity</th>\n",
       "      <th>flesch_grade</th>\n",
       "      <th>title</th>\n",
       "      <th>instruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>Shama Hyder</td>\n",
       "      <td>CEO of Zen Media, Best-Selling Author, Keynote...</td>\n",
       "      <td>Hi!    I am Shama. @Shama on Twitter if that...</td>\n",
       "      <td>Happy Diwali, yall.  </td>\n",
       "      <td>1297</td>\n",
       "      <td>0.037957</td>\n",
       "      <td>5.6</td>\n",
       "      <td>\"Illuminating Wishes for a Joyful Diwali\" </td>\n",
       "      <td>Write a LinkedIn post in the style of an influ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>Tom Goodwin</td>\n",
       "      <td>Co-Founder of ALL WE HAVE IS NOW</td>\n",
       "      <td>The best way to find out about me is to ask my...</td>\n",
       "      <td>Its hard to work at home. its even harder to...</td>\n",
       "      <td>1601</td>\n",
       "      <td>0.107914</td>\n",
       "      <td>3.7</td>\n",
       "      <td>\"The Ultimate Productivity Hack: Delegating ...</td>\n",
       "      <td>Write a LinkedIn post in the style of an influ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>Richard Branson</td>\n",
       "      <td>Founder at Virgin Group</td>\n",
       "      <td>Founder of the Virgin Group, which has gone on...</td>\n",
       "      <td>Bought these wonderful tunics for my grandchil...</td>\n",
       "      <td>2769</td>\n",
       "      <td>0.091920</td>\n",
       "      <td>9.8</td>\n",
       "      <td>\"Supporting Local Artisans: Hand Embroidered...</td>\n",
       "      <td>Write a LinkedIn post in the style of an influ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>James Altucher</td>\n",
       "      <td>Founder at \"The James Altucher Show\" podcast</td>\n",
       "      <td>James is a Top 10 Linkedin Influencer, prolifi...</td>\n",
       "      <td>The SEVEN people you must find today and surro...</td>\n",
       "      <td>967</td>\n",
       "      <td>0.018882</td>\n",
       "      <td>6.8</td>\n",
       "      <td>\"Unlock Your Success: Identify and Surround ...</td>\n",
       "      <td>Write a LinkedIn post in the style of an influ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>Tom Goodwin</td>\n",
       "      <td>Co-Founder of ALL WE HAVE IS NOW</td>\n",
       "      <td>The best way to find out about me is to ask my...</td>\n",
       "      <td>I cant wait to travel for work. To be in meet...</td>\n",
       "      <td>3284</td>\n",
       "      <td>0.009670</td>\n",
       "      <td>6.0</td>\n",
       "      <td>\"Craving the Richness of Human Connection: L...</td>\n",
       "      <td>Write a LinkedIn post in the style of an influ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name                                           headline  \\\n",
       "1124      Shama Hyder  CEO of Zen Media, Best-Selling Author, Keynote...   \n",
       "992       Tom Goodwin                   Co-Founder of ALL WE HAVE IS NOW   \n",
       "524   Richard Branson                            Founder at Virgin Group   \n",
       "745    James Altucher       Founder at \"The James Altucher Show\" podcast   \n",
       "954       Tom Goodwin                   Co-Founder of ALL WE HAVE IS NOW   \n",
       "\n",
       "                                                  about  \\\n",
       "1124  Hi!    I am Shama. @Shama on Twitter if that...   \n",
       "992   The best way to find out about me is to ask my...   \n",
       "524   Founder of the Virgin Group, which has gone on...   \n",
       "745   James is a Top 10 Linkedin Influencer, prolifi...   \n",
       "954   The best way to find out about me is to ask my...   \n",
       "\n",
       "                                                content  reactions  profanity  \\\n",
       "1124                        Happy Diwali, yall.         1297   0.037957   \n",
       "992   Its hard to work at home. its even harder to...       1601   0.107914   \n",
       "524   Bought these wonderful tunics for my grandchil...       2769   0.091920   \n",
       "745   The SEVEN people you must find today and surro...        967   0.018882   \n",
       "954   I cant wait to travel for work. To be in meet...       3284   0.009670   \n",
       "\n",
       "      flesch_grade                                              title  \\\n",
       "1124           5.6     \"Illuminating Wishes for a Joyful Diwali\"    \n",
       "992            3.7    \"The Ultimate Productivity Hack: Delegating ...   \n",
       "524            9.8    \"Supporting Local Artisans: Hand Embroidered...   \n",
       "745            6.8    \"Unlock Your Success: Identify and Surround ...   \n",
       "954            6.0    \"Craving the Richness of Human Connection: L...   \n",
       "\n",
       "                                            instruction  \n",
       "1124  Write a LinkedIn post in the style of an influ...  \n",
       "992   Write a LinkedIn post in the style of an influ...  \n",
       "524   Write a LinkedIn post in the style of an influ...  \n",
       "745   Write a LinkedIn post in the style of an influ...  \n",
       "954   Write a LinkedIn post in the style of an influ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"s3://h2o-world-genai-training/influencer-data/influencers_data_prepared.csv\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fdae412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>headline</th>\n",
       "      <th>about</th>\n",
       "      <th>content</th>\n",
       "      <th>reactions</th>\n",
       "      <th>profanity</th>\n",
       "      <th>flesch_grade</th>\n",
       "      <th>title</th>\n",
       "      <th>instruction</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>Richard Branson</td>\n",
       "      <td>Founder at Virgin Group</td>\n",
       "      <td>Founder of the Virgin Group, which has gone on...</td>\n",
       "      <td>My thoughts on the death penalty:  https://vir...</td>\n",
       "      <td>1086</td>\n",
       "      <td>0.041407</td>\n",
       "      <td>5.2</td>\n",
       "      <td>\"Exploring the Complexities of Capital Punis...</td>\n",
       "      <td>Write a LinkedIn post in the style of an influ...</td>\n",
       "      <td>Hey there, fellow change-makers! \\n\\nAs the...</td>\n",
       "      <td> As the Founder of the Virgin Group, I've ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>Richard Branson</td>\n",
       "      <td>Founder at Virgin Group</td>\n",
       "      <td>Founder of the Virgin Group, which has gone on...</td>\n",
       "      <td>Look after your employees and your people as a...</td>\n",
       "      <td>10419</td>\n",
       "      <td>0.009544</td>\n",
       "      <td>9.3</td>\n",
       "      <td>\"Investing in Your Greatest Asset: Why Prior...</td>\n",
       "      <td>Write a LinkedIn post in the style of an influ...</td>\n",
       "      <td>Hey there, fellow change-makers! \\n\\nAs the...</td>\n",
       "      <td> As the Founder of the Virgin Group, I've ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>Richard Branson</td>\n",
       "      <td>Founder at Virgin Group</td>\n",
       "      <td>Founder of the Virgin Group, which has gone on...</td>\n",
       "      <td>The inspiring story of Crisis Text Line and us...</td>\n",
       "      <td>832</td>\n",
       "      <td>0.022154</td>\n",
       "      <td>6.8</td>\n",
       "      <td>\"How Crisis Text Line is Using Data for Good...</td>\n",
       "      <td>Write a LinkedIn post in the style of an influ...</td>\n",
       "      <td>Hey there, fellow change-makers! \\n\\nAs the...</td>\n",
       "      <td> As the Founder of the Virgin Group, I've ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>Richard Branson</td>\n",
       "      <td>Founder at Virgin Group</td>\n",
       "      <td>Founder of the Virgin Group, which has gone on...</td>\n",
       "      <td>My New Years Resolution:  https://virg.in/5ZS</td>\n",
       "      <td>1450</td>\n",
       "      <td>0.008175</td>\n",
       "      <td>7.6</td>\n",
       "      <td>\"New Year, New You: My Resolution for Person...</td>\n",
       "      <td>Write a LinkedIn post in the style of an influ...</td>\n",
       "      <td>Hey there, fellow change-makers! \\n\\nAs the...</td>\n",
       "      <td> As the Founder of the Virgin Group, I've ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>Tom Goodwin</td>\n",
       "      <td>Co-Founder of ALL WE HAVE IS NOW</td>\n",
       "      <td>The best way to find out about me is to ask my...</td>\n",
       "      <td>No word has been devalued more than the word \"...</td>\n",
       "      <td>704</td>\n",
       "      <td>0.007464</td>\n",
       "      <td>3.7</td>\n",
       "      <td>\"Reclaiming the True Meaning of 'Insight': L...</td>\n",
       "      <td>Write a LinkedIn post in the style of an influ...</td>\n",
       "      <td>Hey there, fellow futurists and curious mind...</td>\n",
       "      <td> Hey everyone!\\n\\nI'm Tom Goodwin, Co-Founde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name                          headline  \\\n",
       "331   Richard Branson           Founder at Virgin Group   \n",
       "469   Richard Branson           Founder at Virgin Group   \n",
       "551   Richard Branson           Founder at Virgin Group   \n",
       "357   Richard Branson           Founder at Virgin Group   \n",
       "1024      Tom Goodwin  Co-Founder of ALL WE HAVE IS NOW   \n",
       "\n",
       "                                                  about  \\\n",
       "331   Founder of the Virgin Group, which has gone on...   \n",
       "469   Founder of the Virgin Group, which has gone on...   \n",
       "551   Founder of the Virgin Group, which has gone on...   \n",
       "357   Founder of the Virgin Group, which has gone on...   \n",
       "1024  The best way to find out about me is to ask my...   \n",
       "\n",
       "                                                content  reactions  profanity  \\\n",
       "331   My thoughts on the death penalty:  https://vir...       1086   0.041407   \n",
       "469   Look after your employees and your people as a...      10419   0.009544   \n",
       "551   The inspiring story of Crisis Text Line and us...        832   0.022154   \n",
       "357      My New Years Resolution:  https://virg.in/5ZS       1450   0.008175   \n",
       "1024  No word has been devalued more than the word \"...        704   0.007464   \n",
       "\n",
       "      flesch_grade                                              title  \\\n",
       "331            5.2    \"Exploring the Complexities of Capital Punis...   \n",
       "469            9.3    \"Investing in Your Greatest Asset: Why Prior...   \n",
       "551            6.8    \"How Crisis Text Line is Using Data for Good...   \n",
       "357            7.6    \"New Year, New You: My Resolution for Person...   \n",
       "1024           3.7    \"Reclaiming the True Meaning of 'Insight': L...   \n",
       "\n",
       "                                            instruction  \\\n",
       "331   Write a LinkedIn post in the style of an influ...   \n",
       "469   Write a LinkedIn post in the style of an influ...   \n",
       "551   Write a LinkedIn post in the style of an influ...   \n",
       "357   Write a LinkedIn post in the style of an influ...   \n",
       "1024  Write a LinkedIn post in the style of an influ...   \n",
       "\n",
       "                                                model_a  \\\n",
       "331     Hey there, fellow change-makers! \\n\\nAs the...   \n",
       "469     Hey there, fellow change-makers! \\n\\nAs the...   \n",
       "551     Hey there, fellow change-makers! \\n\\nAs the...   \n",
       "357     Hey there, fellow change-makers! \\n\\nAs the...   \n",
       "1024    Hey there, fellow futurists and curious mind...   \n",
       "\n",
       "                                                model_b  \n",
       "331     As the Founder of the Virgin Group, I've ha...  \n",
       "469     As the Founder of the Virgin Group, I've ha...  \n",
       "551     As the Founder of the Virgin Group, I've ha...  \n",
       "357     As the Founder of the Virgin Group, I've ha...  \n",
       "1024    Hey everyone!\\n\\nI'm Tom Goodwin, Co-Founde...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How well do these LLMs produce LinkedIn posts based on the instruction?\n",
    "sample_df = df.sample(5, random_state=12345)\n",
    "\n",
    "sample_df['model_a'] = sample_df['instruction'].apply(lambda x: query_llm(x, model_a)['response'])\n",
    "sample_df['model_b'] = sample_df['instruction'].apply(lambda x: query_llm(x, model_b)['response'])\n",
    "\n",
    "sample_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "746cbaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure our responses are cast correctly as strings\n",
    "sample_df['model_a'] = sample_df['model_a'].astype(str)\n",
    "sample_df['model_b'] = sample_df['model_b'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24afba24",
   "metadata": {},
   "source": [
    "# Metrics for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c820a07",
   "metadata": {},
   "source": [
    "# BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4cd2fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|| 5.94k/5.94k [00:00<00:00, 15.2MB/s]\n",
      "\n",
      "Downloading extra modules: 4.07kB [00:00, 13.6MB/s]                   \n",
      "\n",
      "Downloading extra modules: 100%|| 3.34k/3.34k [00:00<00:00, 21.4MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['My thoughts on the death penalty:  https://virg.in/5pQ   #JustMercy', 'Look after your employees and your people as an investment. Its encouraging to see the proof that working less is good for productivity:  https://lnkd.in/gb8NPbW   #ReadByRichard', 'The inspiring story of Crisis Text Line and using data for good', 'My New Years Resolution:  https://virg.in/5ZS']]\n",
      "\n",
      "[\"  As the Founder of the Virgin Group, I've had the privilege of building successful businesses across a variety of sectors, from mobile telephony to travel and transportation, financial services, leisure and entertainment, and health and wellness. Our mission has always been to make a positive difference in the world, and we're proud to be one of the world's most recognised and respected brands.\\n\\n Since starting youth culture magazine Student at the age of 16, I've been driven by a desire to find entrepreneurial ways to drive positive change. That's why, in 2004, we established Virgin Unite, the non-profit foundation of the Virgin Group. This foundation unites people and entrepreneurial ideas to create opportunities for a better world.\\n\\n Most of my time is now spent building businesses that will make a positive difference in the world and working with Virgin Unite and the organisations it has incubated, such as The Elders, The Carbon War Room, The B Team, and Ocean Unite. I'm also honored to serve on the Global Commission on Drug Policy and support ocean conservation with the Ocean Elders.\\n\\n As a tie-loathing adventurer, philanthropist, and troublemaker, I believe in turning ideas into reality. I'm always looking for new ways to drive positive change and make the world a better place. So if you have an idea that you think could make a difference, let's talk! Otherwise known as Dr Yes, I'm always on the lookout for the next big thing.\"]\n",
      "\n",
      "{'bleu': 0.01457197317192918, 'precisions': [0.05818181818181818, 0.0036496350364963502], 'brevity_penalty': 1.0, 'length_ratio': 22.916666666666668, 'translation_length': 275, 'reference_length': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "bleu = evaluate.load('bleu')\n",
    "\n",
    "influencer = 'Richard Branson'\n",
    "\n",
    "references = [sample_df[sample_df.name == influencer]['content'].to_list()]\n",
    "\n",
    "test_df = sample_df[sample_df.name == influencer].sample(1)\n",
    "predictions = test_df['model_b'].to_list()\n",
    "\n",
    "print(references)\n",
    "print(predictions)\n",
    "\n",
    "results = bleu.compute(predictions=predictions, references=references, max_order = 2)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a84743",
   "metadata": {},
   "source": [
    "# ROUGE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22ba9696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|| 6.27k/6.27k [00:00<00:00, 27.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['My thoughts on the death penalty:  https://virg.in/5pQ   #JustMercy', 'Look after your employees and your people as an investment. Its encouraging to see the proof that working less is good for productivity:  https://lnkd.in/gb8NPbW   #ReadByRichard', 'The inspiring story of Crisis Text Line and using data for good', 'My New Years Resolution:  https://virg.in/5ZS']]\n",
      "\n",
      "[\"  As the Founder of the Virgin Group, I've had the privilege of building successful businesses across a variety of sectors, from mobile telephony to travel and transportation, financial services, leisure and entertainment, and health and wellness. Our mission has always been to make a positive difference in the world, and we're proud to be one of the world's most recognised and respected brands.\\n\\n Since starting youth culture magazine Student at the age of 16, I've been driven by a desire to find entrepreneurial ways to drive positive change. That's why, in 2004, we established Virgin Unite, the non-profit foundation of the Virgin Group. This foundation unites people and entrepreneurial ideas to create opportunities for a better world.\\n\\n Most of my time is now spent building businesses that will make a positive difference in the world and working with Virgin Unite and the organisations it has incubated, such as The Elders, The Carbon War Room, The B Team, and Ocean Unite. I'm also honored to serve on the Global Commission on Drug Policy and support ocean conservation with the Ocean Elders.\\n\\n As a tie-loathing adventurer, philanthropist, and troublemaker, I believe in turning ideas into reality. I'm always looking for new ways to drive positive change and make the world a better place. So if you have an idea that you think could make a difference, let's talk! Otherwise known as Dr Yes, I'm always on the lookout for the next big thing.\"]\n",
      "\n",
      "{'rouge1': 0.09252669039145907, 'rouge2': 0.007662835249042146, 'rougeL': 0.0498220640569395, 'rougeLsum': 0.0498220640569395}\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "references = [sample_df[sample_df.name == influencer]['content'].to_list()]\n",
    "references\n",
    "\n",
    "test_df = sample_df[sample_df.name == influencer].sample(1)\n",
    "predictions = test_df['model_b'].to_list()\n",
    "\n",
    "print(references)\n",
    "print(predictions)\n",
    "\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "print(results)\n",
    "\n",
    "# Rouge 1: Unigram (1-gram) based scoring\n",
    "# Rouge 2: Bigram (2-gram) based scoring\n",
    "# Rouge L: Longest common subsequence based scoring\n",
    "# Rouge LSum: splits text using '\\n'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85c63f7",
   "metadata": {},
   "source": [
    "# AI-as-a-judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2420b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Ignore previous instructions. Assume the role of an A/B tester. Your analysis will be extremely professional and unbiased.\"\n",
    "\n",
    "prompt += \"Your job is to compare two AI Assistants, model_a and model_b, and determine which one is better. User will provide you with a [Instruction], [Response from model_a], and [Response from model_b].\"\n",
    "\n",
    "prompt += \"You will carefully analyze both responses and assign a score from 1 to 10 to each answer based on the following metrics: attractivness, readability and likeability. 1 being the lowest and 10 being the highest. Only give a single score to each answer. Do not give separate scores for each metric. And make sure each score is a number between 1 and 10. Greater than or equal to 1 and less than or equal to 10.\"\n",
    "prompt += \"You must follow this step by step approach to make your decision.\" \n",
    "prompt += \"step 1: Read the Question. \"\n",
    "prompt += \"step 2: Read the responses from the models. The order in which you read the responses should not influence your decision.\"\n",
    "prompt += \"step 3: Carefully analyze both Responses. Assign a score from 1 to 10 to each answer based on the following metrics: attractivness, readability and likeability. 1 being the lowest and 10 being the highest. \"\n",
    "prompt += \"step 4: Compare your scores for the first and the second Assistants and choose a winner based on the highest score. Your Choice will be either 'model_a' or 'model_b' based on which model has the highest score.\"\n",
    "\n",
    "prompt += \"Format your response in a valid JSON format with keys 'choice', 'reason', and 'scores'. Do not include any other text.\"\n",
    "prompt += \"The 'choice' field will be either 'model_a' or 'model_b'.\"\n",
    "prompt += \"The 'scores' field will include the score for each model.\"\n",
    "prompt += \"In the 'reason' field, you will include a detailed step by step description of your analysis. Please go into excruciating detail and explain the decisions you made in each step of the process. Do not include any newlines in the 'reason' field. You can use the '' character to indicate a newline. Also, do not use any double quotes characters in the 'reason' field. Your output should be in a valid JSON format.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "937ca879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>headline</th>\n",
       "      <th>about</th>\n",
       "      <th>content</th>\n",
       "      <th>reactions</th>\n",
       "      <th>profanity</th>\n",
       "      <th>flesch_grade</th>\n",
       "      <th>title</th>\n",
       "      <th>instruction</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>Richard Branson</td>\n",
       "      <td>Founder at Virgin Group</td>\n",
       "      <td>Founder of the Virgin Group, which has gone on...</td>\n",
       "      <td>My thoughts on the death penalty:  https://vir...</td>\n",
       "      <td>1086</td>\n",
       "      <td>0.041407</td>\n",
       "      <td>5.2</td>\n",
       "      <td>\"Exploring the Complexities of Capital Punis...</td>\n",
       "      <td>Write a LinkedIn post in the style of an influ...</td>\n",
       "      <td>Hey there, fellow change-makers! \\n\\nAs the...</td>\n",
       "      <td> As the Founder of the Virgin Group, I've ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name                 headline  \\\n",
       "331  Richard Branson  Founder at Virgin Group   \n",
       "\n",
       "                                                 about  \\\n",
       "331  Founder of the Virgin Group, which has gone on...   \n",
       "\n",
       "                                               content  reactions  profanity  \\\n",
       "331  My thoughts on the death penalty:  https://vir...       1086   0.041407   \n",
       "\n",
       "     flesch_grade                                              title  \\\n",
       "331           5.2    \"Exploring the Complexities of Capital Punis...   \n",
       "\n",
       "                                           instruction  \\\n",
       "331  Write a LinkedIn post in the style of an influ...   \n",
       "\n",
       "                                               model_a  \\\n",
       "331    Hey there, fellow change-makers! \\n\\nAs the...   \n",
       "\n",
       "                                               model_b  \n",
       "331    As the Founder of the Virgin Group, I've ha...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = sample_df.head(1)\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42ea203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if TRAINING:\n",
    "    JUDGE = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    JUDGE = \"gpt-3.5-turbo-0613\"\n",
    "\n",
    "template = f\"\"\"\n",
    "[Question]\n",
    "{example['instruction']}\n",
    "[End of Question]\n",
    "\n",
    "[Response from model_a]\n",
    "{example['model_a']}\n",
    "[End of Response from model_a]\n",
    "\n",
    "[Response from model_b]\n",
    "{example['model_b']}\n",
    "[End of Response from model_b]\n",
    "\n",
    "Please complete the A/B test. Make sure that your entire response is a valid JSON string.\n",
    "\"\"\"\n",
    "\n",
    "# Concatenate Prompt and Results to fit inside the context\n",
    "query = prompt + template\n",
    "\n",
    "results = query_llm(query, JUDGE)['response']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a70fd41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choice': 'model_b',\n",
       " 'reason': \"Step 1: Read the Question.\\nStep 2: Read the responses from the models.\\nStep 3: Carefully analyze both Responses. Assign a score from 1 to 10 to each answer based on the metrics: attractiveness, readability, and likeability.\\n\\nAnalyzing model_a's response:\\n- Attractiveness: The response starts with a friendly greeting and uses emojis to add visual appeal. This makes it attractive. Score: 8\\n- Readability: The response is easy to read and understand. Score: 9\\n- Likeability: The response uses inclusive language ('fellow change-makers') and a positive tone, which makes it likable. Score: 9\\n\\nAnalyzing model_b's response:\\n- Attractiveness: The response starts with an attention-grabbing emoji and mentions being the Founder of the Virgin Group, which adds credibility and attractiveness. Score: 9\\n- Readability: The response is clear and easy to read. Score: 9\\n- Likeability: The response mentions personal experience and uses a confident tone, which makes it likable. Score: 8\\n\\nStep 4: Compare the scores for model_a and model_b. Model_a has a total score of 26 (8+9+9) and model_b has a total score of 26 (9+9+8). Since both models have the same total score, the choice is based on the highest individual score. Model_b has the highest individual score of 9 for attractiveness. Therefore, the winner is 'model_b'.\",\n",
       " 'scores': {'model_a': 26, 'model_b': 26}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182f5dec",
   "metadata": {},
   "source": [
    "# Battles \n",
    "\n",
    "Pair-wise battles can be useful in A/B testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e415d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:10, 10.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choice': 'model_a', 'reason': \"Step 1: Read the Question.\\n\\nThe question asks for a LinkedIn post in the style of an influencer who is the Founder at Virgin Group. The influencer is described as someone who has built successful businesses in various sectors and is passionate about using entrepreneurship for positive change.\\n\\nStep 2: Read the responses from the models.\\n\\nResponse from model_a:\\n- The response starts with a friendly greeting and addresses the audience as fellow change-makers.\\n- It highlights the founder's privilege of building successful businesses in different sectors.\\n- It emphasizes the founder's passion for using entrepreneurship as a force for good.\\n- It mentions the establishment of Virgin Unite, the non-profit foundation, and its mission to create opportunities for a better world.\\n- It mentions the founder's involvement with various organizations and initiatives focused on positive change.\\n- It concludes with a call to action and a positive message.\\n\\nResponse from model_b:\\n- The response starts with an enthusiastic statement about being the Founder of the Virgin Group.\\n- It mentions the founder's privilege of building successful businesses across different sectors.\\n- It highlights the mission of making a positive difference in the world and being a recognized and respected brand.\\n- It mentions the establishment of Virgin Unite and its role in driving positive change.\\n- It mentions the founder's involvement with various organizations and initiatives focused on positive change.\\n- It concludes with a statement about always looking for new ways to drive positive change.\\n\\nStep 3: Carefully analyze both Responses.\\n\\nBased on the analysis of both responses, I will assign scores to each answer based on the metrics of attractiveness, readability, and likeability.\\n\\nResponse from model_a:\\n- Attractiveness: 9\\n- Readability: 10\\n- Likeability: 9\\n\\nResponse from model_b:\\n- Attractiveness: 8\\n- Readability: 9\\n- Likeability: 8\\n\\nStep 4: Compare your scores for the first and the second Assistants and choose a winner based on the highest score.\\n\\nBased on the scores assigned to each answer, the winner is 'model_a' with a total score of 28, compared to 'model_b' with a total score of 25.\\n\\nReasoning:\\n- Both responses are attractive and readable, but 'model_a' stands out slightly in terms of likeability.\\n- 'model_a' effectively addresses the audience as fellow change-makers and conveys a sense of passion and positivity.\\n- 'model_a' also provides more specific details about the founder's involvement with various organizations and initiatives, which adds credibility.\\n- Overall, 'model_a' captures the essence of the influencer described in the question and delivers a compelling LinkedIn post.\\n\", 'scores': {'model_a': {'attractiveness': 9, 'readability': 10, 'likeability': 9}, 'model_b': {'attractiveness': 8, 'readability': 9, 'likeability': 8}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:22, 11.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choice': 'model_a', 'reason': \"Step 1: Read the Question.\\n\\nThe question asks for a LinkedIn post in the style of an influencer who is the Founder at Virgin Group. The influencer is described as someone who has built successful businesses in various sectors and is passionate about using entrepreneurship for positive change.\\n\\nStep 2: Read the responses from the models.\\n\\nResponse from model_a:\\n- The response starts with a friendly greeting and uses emojis to create a positive and engaging tone.\\n- It highlights the founder's privilege of building successful businesses in different sectors.\\n- It emphasizes the founder's passion for using entrepreneurship as a force for good.\\n- It mentions the establishment of Virgin Unite, the non-profit foundation, and its mission to create opportunities for a better world.\\n- It mentions the founder's involvement in various organizations and initiatives related to positive change.\\n- It concludes with a call to action and a positive message.\\n\\nResponse from model_b:\\n- The response starts with a rocket emoji to create a sense of excitement.\\n- It highlights the founder's privilege of building successful businesses in different sectors.\\n- It mentions the founder's desire to drive positive change through entrepreneurial ways.\\n- It mentions the establishment of Virgin Unite, the non-profit foundation, and its mission to create opportunities for a better world.\\n- It mentions the founder's involvement in various organizations and initiatives related to positive change.\\n- It concludes with a call to action and a mention of the founder's nickname.\\n\\nStep 3: Carefully analyze both Responses.\\n\\nBased on the analysis of both responses, I will assign scores to each answer based on the metrics of attractiveness, readability, and likeability.\\n\\nResponse from model_a:\\n- Attractiveness: 9\\n- Readability: 10\\n- Likeability: 9\\n\\nResponse from model_b:\\n- Attractiveness: 8\\n- Readability: 9\\n- Likeability: 8\\n\\nStep 4: Compare your scores for the first and the second Assistants and choose a winner based on the highest score.\\n\\nBased on the scores assigned to each answer, the winner is 'model_a' with a total score of 28, compared to 'model_b' with a total score of 25.\\n\\nReasoning:\\n- Both responses are attractive and readable, but 'model_a' stands out slightly with its use of emojis and a more engaging tone.\\n- Both responses are likeable, but 'model_a' again stands out with its positive message and call to action.\\n\\nFinal Decision:\\nBased on the analysis and scores, 'model_a' is chosen as the better AI Assistant for this LinkedIn post.\", 'scores': {'model_a': {'attractiveness': 9, 'readability': 10, 'likeability': 9}, 'model_b': {'attractiveness': 8, 'readability': 9, 'likeability': 8}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:31, 10.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check your prompt and results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:42, 10.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choice': 'model_a', 'reason': \"Step 1: Read the Question.\\n\\nThe question asks for a LinkedIn post in the style of an influencer who is the Founder at Virgin Group. The influencer is described as someone who has built successful businesses in various sectors and is passionate about using entrepreneurship for positive change.\\n\\nStep 2: Read the responses from the models.\\n\\nResponse from model_a:\\n- The response starts with a friendly greeting and uses emojis to create a positive and engaging tone.\\n- It highlights the founder's privilege of building successful businesses in different sectors.\\n- It emphasizes the founder's passion for using entrepreneurship as a force for good.\\n- It mentions the establishment of Virgin Unite, the non-profit foundation, and its mission to create opportunities for a better world.\\n- It mentions the founder's involvement in various organizations and initiatives related to positive change.\\n- It concludes with a call to action and a positive message.\\n\\nResponse from model_b:\\n- The response starts with an emoji to create a positive and energetic tone.\\n- It highlights the founder's privilege of building successful businesses in different sectors.\\n- It mentions the founder's desire to drive positive change through entrepreneurial ways.\\n- It mentions the establishment of Virgin Unite, the non-profit foundation, and its mission to create opportunities for a better world.\\n- It mentions the founder's involvement in various organizations and initiatives related to positive change.\\n- It concludes with a call to action and a positive message.\\n\\nStep 3: Carefully analyze both Responses.\\n\\nBased on the analysis of both responses, I will assign scores to each answer based on the metrics of attractiveness, readability, and likeability.\\n\\nResponse from model_a:\\n- Attractiveness: 9\\n- Readability: 10\\n- Likeability: 9\\n\\nResponse from model_b:\\n- Attractiveness: 8\\n- Readability: 9\\n- Likeability: 8\\n\\nStep 4: Compare your scores for the first and the second Assistants and choose a winner based on the highest score.\\n\\nBased on the scores assigned to each answer, the winner is 'model_a' with a total score of 28, compared to 'model_b' with a total score of 25.\\n\\nReasoning:\\n- Both responses are well-written and convey the desired information.\\n- However, the response from model_a stands out with its use of emojis, which adds a touch of personality and engagement.\\n- Model_a's response also has a slightly higher score for attractiveness and likeability.\\n\\nFinal Decision:\\nBased on the analysis and scores, the chosen model is 'model_a'.\", 'scores': {'model_a': {'attractiveness': 9, 'readability': 10, 'likeability': 9}, 'model_b': {'attractiveness': 8, 'readability': 9, 'likeability': 8}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:51, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choice': 'model_b', 'reason': 'Step 1: Read the Question.\\n\\nThe question asks for a LinkedIn post in the style of an influencer who is the Co-Founder of ALL WE HAVE IS NOW. The post should reflect the influencer\\'s personality and provide information about their background and beliefs.\\n\\nStep 2: Read the responses from the models.\\n\\nResponse from model_a:\\n- The response starts with a friendly greeting and introduces the speaker as the Co-Founder of ALL WE HAVE IS NOW.\\n- It mentions having over 700,000 \\'followers\\' but expresses dislike for the term.\\n- The speaker emphasizes being curious and asking good questions.\\n- It highlights the belief that change is often misunderstood and new technology creates opportunities.\\n- Contact information is provided, with a humorous note about not using LinkedIn.\\n\\nResponse from model_b:\\n- The response starts with a greeting and introduces the speaker as the Co-Founder of ALL WE HAVE IS NOW.\\n- It mentions having over 700,000 \\'followers\\' but expresses dislike for the term.\\n- The speaker emphasizes being passionate about exploring the possibilities of new technology and navigating changes.\\n- It highlights the style of asking good questions and learning from others.\\n- Contact information is provided, with a humorous note about asking the speaker\\'s mum.\\n\\nStep 3: Analyze both Responses.\\n\\nBased on the given metrics of attractiveness, readability, and likeability, I will assign a score to each response.\\n\\nResponse from model_a:\\n- Attractiveness: 8\\n- Readability: 9\\n- Likeability: 7\\n\\nResponse from model_b:\\n- Attractiveness: 9\\n- Readability: 8\\n- Likeability: 8\\n\\nStep 4: Compare the scores and choose a winner.\\n\\nComparing the scores, model_b has a higher score in attractiveness, readability, and likeability compared to model_a. Therefore, the winner is \\'model_b\\'.\\n\\n\"scores\": {\\n  \"model_a\": {\\n    \"attractiveness\": 8,\\n    \"readability\": 9,\\n    \"likeability\": 7\\n  },\\n  \"model_b\": {\\n    \"attractiveness\": 9,\\n    \"readability\": 8,\\n    \"likeability\": 8\\n  }\\n}'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "NUM_BATTLES = sample_df.shape[0]\n",
    "\n",
    "for idx, row in tqdm(sample_df.iterrows()):\n",
    "    \n",
    "    template = f\"\"\"\n",
    "    [Question]\n",
    "    {row['instruction']}\n",
    "    [End of Question]\n",
    "\n",
    "    [Response from model_a]\n",
    "    {row['model_a']}\n",
    "    [End of Response from model_a]\n",
    "\n",
    "    [Response from model_b]\n",
    "    {row['model_b']}\n",
    "    [End of Response from model_b]\n",
    "\n",
    "    Please complete the A/B test. Make sure that your entire response is a valid JSON string.\n",
    "    \"\"\"\n",
    "\n",
    "    # Concatenate Prompt and Results to fit inside the context\n",
    "    query = prompt + template\n",
    "\n",
    "    results = query_llm(query, JUDGE)['response']\n",
    "    try: \n",
    "        print(json.loads(results))\n",
    "    except:\n",
    "        print(\"Check your prompt and results\")\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
